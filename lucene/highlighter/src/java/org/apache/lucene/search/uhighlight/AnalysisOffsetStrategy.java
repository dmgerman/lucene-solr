begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.lucene.search.uhighlight
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|uhighlight
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|automaton
operator|.
name|CharacterRunAutomaton
import|;
end_import

begin_comment
comment|/**  * Provides a base class for analysis based offset strategies to extend from.  * Requires an Analyzer and provides an override-able method for altering how  * the TokenStream is created.  *  * @lucene.internal  */
end_comment

begin_class
DECL|class|AnalysisOffsetStrategy
specifier|public
specifier|abstract
class|class
name|AnalysisOffsetStrategy
extends|extends
name|FieldOffsetStrategy
block|{
DECL|field|analyzer
specifier|protected
specifier|final
name|Analyzer
name|analyzer
decl_stmt|;
DECL|method|AnalysisOffsetStrategy
specifier|public
name|AnalysisOffsetStrategy
parameter_list|(
name|String
name|field
parameter_list|,
name|BytesRef
index|[]
name|queryTerms
parameter_list|,
name|PhraseHelper
name|phraseHelper
parameter_list|,
name|CharacterRunAutomaton
index|[]
name|automata
parameter_list|,
name|Analyzer
name|analyzer
parameter_list|)
block|{
name|super
argument_list|(
name|field
argument_list|,
name|queryTerms
argument_list|,
name|phraseHelper
argument_list|,
name|automata
argument_list|)
expr_stmt|;
name|this
operator|.
name|analyzer
operator|=
name|analyzer
expr_stmt|;
if|if
condition|(
name|analyzer
operator|.
name|getOffsetGap
argument_list|(
name|field
argument_list|)
operator|!=
literal|1
condition|)
block|{
comment|// note: 1 is the default. It is RARELY changed.
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"offset gap of the provided analyzer should be 1 (field "
operator|+
name|field
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|getOffsetSource
specifier|public
specifier|final
name|UnifiedHighlighter
operator|.
name|OffsetSource
name|getOffsetSource
parameter_list|()
block|{
return|return
name|UnifiedHighlighter
operator|.
name|OffsetSource
operator|.
name|ANALYSIS
return|;
block|}
DECL|method|tokenStream
specifier|protected
name|TokenStream
name|tokenStream
parameter_list|(
name|String
name|content
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If there is no splitChar in content then we needn't wrap:
name|int
name|splitCharIdx
init|=
name|content
operator|.
name|indexOf
argument_list|(
name|UnifiedHighlighter
operator|.
name|MULTIVAL_SEP_CHAR
argument_list|)
decl_stmt|;
if|if
condition|(
name|splitCharIdx
operator|==
operator|-
literal|1
condition|)
block|{
return|return
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|field
argument_list|,
name|content
argument_list|)
return|;
block|}
name|TokenStream
name|subTokenStream
init|=
name|analyzer
operator|.
name|tokenStream
argument_list|(
name|field
argument_list|,
name|content
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|splitCharIdx
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|MultiValueTokenStream
argument_list|(
name|subTokenStream
argument_list|,
name|field
argument_list|,
name|analyzer
argument_list|,
name|content
argument_list|,
name|UnifiedHighlighter
operator|.
name|MULTIVAL_SEP_CHAR
argument_list|,
name|splitCharIdx
argument_list|)
return|;
block|}
comment|/**    * Wraps an {@link Analyzer} and string text that represents multiple values delimited by a specified character. This    * exposes a TokenStream that matches what would get indexed considering the    * {@link Analyzer#getPositionIncrementGap(String)}. Currently this assumes {@link Analyzer#getOffsetGap(String)} is    * 1; an exception will be thrown if it isn't.    *<br />    * It would be more orthogonal for this to be an Analyzer since we're wrapping an Analyzer but doing so seems like    * more work.  The underlying components see a Reader not a String -- and the String is easy to    * split up without redundant buffering.    *    * @lucene.internal    */
comment|// TODO we could make this go away.  MemoryIndexOffsetStrategy could simply split and analyze each value into the
comment|//   MemoryIndex. TokenStreamOffsetStrategy's hack TokenStreamPostingsEnum could incorporate this logic,
comment|//   albeit with less code, less hack.
DECL|class|MultiValueTokenStream
specifier|private
specifier|static
specifier|final
class|class
name|MultiValueTokenStream
extends|extends
name|TokenFilter
block|{
DECL|field|fieldName
specifier|private
specifier|final
name|String
name|fieldName
decl_stmt|;
DECL|field|indexAnalyzer
specifier|private
specifier|final
name|Analyzer
name|indexAnalyzer
decl_stmt|;
DECL|field|content
specifier|private
specifier|final
name|String
name|content
decl_stmt|;
DECL|field|splitChar
specifier|private
specifier|final
name|char
name|splitChar
decl_stmt|;
DECL|field|posIncAtt
specifier|private
specifier|final
name|PositionIncrementAttribute
name|posIncAtt
init|=
name|addAttribute
argument_list|(
name|PositionIncrementAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|offsetAtt
specifier|private
specifier|final
name|OffsetAttribute
name|offsetAtt
init|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|startValIdx
specifier|private
name|int
name|startValIdx
init|=
literal|0
decl_stmt|;
DECL|field|endValIdx
specifier|private
name|int
name|endValIdx
decl_stmt|;
DECL|field|remainingPosInc
specifier|private
name|int
name|remainingPosInc
init|=
literal|0
decl_stmt|;
DECL|method|MultiValueTokenStream
specifier|private
name|MultiValueTokenStream
parameter_list|(
name|TokenStream
name|subTokenStream
parameter_list|,
name|String
name|fieldName
parameter_list|,
name|Analyzer
name|indexAnalyzer
parameter_list|,
name|String
name|content
parameter_list|,
name|char
name|splitChar
parameter_list|,
name|int
name|splitCharIdx
parameter_list|)
block|{
name|super
argument_list|(
name|subTokenStream
argument_list|)
expr_stmt|;
comment|// subTokenStream is already initialized to operate on the first value
name|this
operator|.
name|fieldName
operator|=
name|fieldName
expr_stmt|;
name|this
operator|.
name|indexAnalyzer
operator|=
name|indexAnalyzer
expr_stmt|;
name|this
operator|.
name|content
operator|=
name|content
expr_stmt|;
name|this
operator|.
name|splitChar
operator|=
name|splitChar
expr_stmt|;
name|this
operator|.
name|endValIdx
operator|=
name|splitCharIdx
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|startValIdx
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"This TokenStream wasn't developed to be re-used."
argument_list|)
throw|;
comment|// ... although we could if a need for it arises.
block|}
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|incrementToken
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
name|input
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
comment|// Position tracking:
if|if
condition|(
name|remainingPosInc
operator|>
literal|0
condition|)
block|{
comment|//usually true first token of additional values (not first val)
name|posIncAtt
operator|.
name|setPositionIncrement
argument_list|(
name|remainingPosInc
operator|+
name|posIncAtt
operator|.
name|getPositionIncrement
argument_list|()
argument_list|)
expr_stmt|;
name|remainingPosInc
operator|=
literal|0
expr_stmt|;
comment|//reset
block|}
comment|// Offset tracking:
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|startValIdx
operator|+
name|offsetAtt
operator|.
name|startOffset
argument_list|()
argument_list|,
name|startValIdx
operator|+
name|offsetAtt
operator|.
name|endOffset
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
if|if
condition|(
name|endValIdx
operator|==
name|content
operator|.
name|length
argument_list|()
condition|)
block|{
comment|//no more
return|return
literal|false
return|;
block|}
name|input
operator|.
name|end
argument_list|()
expr_stmt|;
comment|// might adjust position increment
name|remainingPosInc
operator|+=
name|posIncAtt
operator|.
name|getPositionIncrement
argument_list|()
expr_stmt|;
name|input
operator|.
name|close
argument_list|()
expr_stmt|;
name|remainingPosInc
operator|+=
name|indexAnalyzer
operator|.
name|getPositionIncrementGap
argument_list|(
name|fieldName
argument_list|)
expr_stmt|;
comment|// Get new tokenStream based on next segment divided by the splitChar
name|startValIdx
operator|=
name|endValIdx
operator|+
literal|1
expr_stmt|;
name|endValIdx
operator|=
name|content
operator|.
name|indexOf
argument_list|(
name|splitChar
argument_list|,
name|startValIdx
argument_list|)
expr_stmt|;
if|if
condition|(
name|endValIdx
operator|==
operator|-
literal|1
condition|)
block|{
comment|//EOF
name|endValIdx
operator|=
name|content
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
name|TokenStream
name|tokenStream
init|=
name|indexAnalyzer
operator|.
name|tokenStream
argument_list|(
name|fieldName
argument_list|,
name|content
operator|.
name|substring
argument_list|(
name|startValIdx
argument_list|,
name|endValIdx
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|tokenStream
operator|!=
name|input
condition|)
block|{
comment|// (input is defined in TokenFilter set in the constructor)
comment|// This is a grand trick we do -- knowing that the analyzer's re-use strategy is going to produce the
comment|// very same tokenStream instance and thus have the same AttributeSource as this wrapping TokenStream
comment|// since we used it as our input in the constructor.
comment|// Were this not the case, we'd have to copy every attribute of interest since we can't alter the
comment|// AttributeSource of this wrapping TokenStream post-construction (it's all private/final).
comment|// If this is a problem, we could do that instead; maybe with a custom CharTermAttribute that allows
comment|// us to easily set the char[] reference without literally copying char by char.
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Require TokenStream re-use.  Unsupported re-use strategy?: "
operator|+
name|indexAnalyzer
operator|.
name|getReuseStrategy
argument_list|()
argument_list|)
throw|;
block|}
name|tokenStream
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
comment|// while loop to increment token of this new value
block|}
annotation|@
name|Override
DECL|method|end
specifier|public
name|void
name|end
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|end
argument_list|()
expr_stmt|;
comment|// Offset tracking:
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|startValIdx
operator|+
name|offsetAtt
operator|.
name|startOffset
argument_list|()
argument_list|,
name|startValIdx
operator|+
name|offsetAtt
operator|.
name|endOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

