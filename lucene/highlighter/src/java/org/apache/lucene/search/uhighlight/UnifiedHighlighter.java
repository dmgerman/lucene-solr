begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.lucene.search.uhighlight
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|uhighlight
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|BreakIterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Locale
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Supplier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Analyzer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|document
operator|.
name|FieldType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|BaseCompositeReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FieldInfos
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Fields
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|FilterLeafReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexOptions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReaderContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MultiFields
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MultiReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|StoredFieldVisitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Term
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|DocIdSetIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|IndexSearcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|MultiTermQuery
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Query
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|ScoreDoc
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|TopDocs
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|Weight
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|spans
operator|.
name|SpanQuery
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|InPlaceMergeSorter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|UnicodeUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|automaton
operator|.
name|CharacterRunAutomaton
import|;
end_import

begin_comment
comment|/**  * A Highlighter that can get offsets from either  * postings ({@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}),  * term vectors ({@link FieldType#setStoreTermVectorOffsets(boolean)}),  * or via re-analyzing text.  *<p>  * This highlighter treats the single original document as the whole corpus, and then scores individual  * passages as if they were documents in this corpus. It uses a {@link BreakIterator} to find  * passages in the text; by default it breaks using {@link BreakIterator#getSentenceInstance(Locale)  * getSentenceInstance(Locale.ROOT)}. It then iterates in parallel (merge sorting by offset) through  * the positions of all terms from the query, coalescing those hits that occur in a single passage  * into a {@link Passage}, and then scores each Passage using a separate {@link PassageScorer}.  * Passages are finally formatted into highlighted snippets with a {@link PassageFormatter}.  *<p>  * You can customize the behavior by calling some of the setters, or by subclassing and overriding some methods.  * Some important hooks:  *<ul>  *<li>{@link #getBreakIterator(String)}: Customize how the text is divided into passages.  *<li>{@link #getScorer(String)}: Customize how passages are ranked.  *<li>{@link #getFormatter(String)}: Customize how snippets are formatted.  *</ul>  *<p>  * This is thread-safe.  *  * @lucene.experimental  */
end_comment

begin_class
DECL|class|UnifiedHighlighter
specifier|public
class|class
name|UnifiedHighlighter
block|{
DECL|field|MULTIVAL_SEP_CHAR
specifier|protected
specifier|static
specifier|final
name|char
name|MULTIVAL_SEP_CHAR
init|=
operator|(
name|char
operator|)
literal|0
decl_stmt|;
DECL|field|DEFAULT_MAX_LENGTH
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_LENGTH
init|=
literal|10000
decl_stmt|;
DECL|field|DEFAULT_CACHE_CHARS_THRESHOLD
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_CACHE_CHARS_THRESHOLD
init|=
literal|524288
decl_stmt|;
comment|// ~ 1 MB (2 byte chars)
DECL|field|EMPTY_INDEXSEARCHER
specifier|static
specifier|final
name|IndexSearcher
name|EMPTY_INDEXSEARCHER
decl_stmt|;
static|static
block|{
try|try
block|{
name|IndexReader
name|emptyReader
init|=
operator|new
name|MultiReader
argument_list|()
decl_stmt|;
name|EMPTY_INDEXSEARCHER
operator|=
operator|new
name|IndexSearcher
argument_list|(
name|emptyReader
argument_list|)
expr_stmt|;
name|EMPTY_INDEXSEARCHER
operator|.
name|setQueryCache
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|bogus
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|bogus
argument_list|)
throw|;
block|}
block|}
DECL|field|ZERO_LEN_AUTOMATA_ARRAY
specifier|protected
specifier|static
specifier|final
name|CharacterRunAutomaton
index|[]
name|ZERO_LEN_AUTOMATA_ARRAY
init|=
operator|new
name|CharacterRunAutomaton
index|[
literal|0
index|]
decl_stmt|;
DECL|field|searcher
specifier|protected
specifier|final
name|IndexSearcher
name|searcher
decl_stmt|;
comment|// if null, can only use highlightWithoutSearcher
DECL|field|indexAnalyzer
specifier|protected
specifier|final
name|Analyzer
name|indexAnalyzer
decl_stmt|;
DECL|field|defaultHandleMtq
specifier|private
name|boolean
name|defaultHandleMtq
init|=
literal|true
decl_stmt|;
comment|// e.g. wildcards
DECL|field|defaultHighlightPhrasesStrictly
specifier|private
name|boolean
name|defaultHighlightPhrasesStrictly
init|=
literal|true
decl_stmt|;
comment|// AKA "accuracy" or "query debugging"
comment|// private boolean defaultRequireFieldMatch = true; TODO
DECL|field|maxLength
specifier|private
name|int
name|maxLength
init|=
name|DEFAULT_MAX_LENGTH
decl_stmt|;
comment|// BreakIterator is stateful so we use a Supplier factory method
DECL|field|defaultBreakIterator
specifier|private
name|Supplier
argument_list|<
name|BreakIterator
argument_list|>
name|defaultBreakIterator
init|=
parameter_list|()
lambda|->
name|BreakIterator
operator|.
name|getSentenceInstance
argument_list|(
name|Locale
operator|.
name|ROOT
argument_list|)
decl_stmt|;
DECL|field|defaultScorer
specifier|private
name|PassageScorer
name|defaultScorer
init|=
operator|new
name|PassageScorer
argument_list|()
decl_stmt|;
DECL|field|defaultFormatter
specifier|private
name|PassageFormatter
name|defaultFormatter
init|=
operator|new
name|DefaultPassageFormatter
argument_list|()
decl_stmt|;
DECL|field|defaultMaxNoHighlightPassages
specifier|private
name|int
name|defaultMaxNoHighlightPassages
init|=
operator|-
literal|1
decl_stmt|;
comment|// lazy initialized with double-check locking; protected so subclass can init
DECL|field|fieldInfos
specifier|protected
specifier|volatile
name|FieldInfos
name|fieldInfos
decl_stmt|;
DECL|field|cacheFieldValCharsThreshold
specifier|private
name|int
name|cacheFieldValCharsThreshold
init|=
name|DEFAULT_CACHE_CHARS_THRESHOLD
decl_stmt|;
comment|/**    * Calls {@link Weight#extractTerms(Set)} on an empty index for the query.    */
DECL|method|extractTerms
specifier|protected
specifier|static
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|extractTerms
parameter_list|(
name|Query
name|query
parameter_list|)
throws|throws
name|IOException
block|{
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|queryTerms
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
decl_stmt|;
name|EMPTY_INDEXSEARCHER
operator|.
name|createNormalizedWeight
argument_list|(
name|query
argument_list|,
literal|false
argument_list|)
operator|.
name|extractTerms
argument_list|(
name|queryTerms
argument_list|)
expr_stmt|;
return|return
name|queryTerms
return|;
block|}
comment|/**    * Constructs the highlighter with the given index searcher and analyzer.    *    * @param indexSearcher Usually required, unless {@link #highlightWithoutSearcher(String, Query, String, int)} is    *                      used, in which case this needs to be null.    * @param indexAnalyzer Required, even if in some circumstances it isn't used.    */
DECL|method|UnifiedHighlighter
specifier|public
name|UnifiedHighlighter
parameter_list|(
name|IndexSearcher
name|indexSearcher
parameter_list|,
name|Analyzer
name|indexAnalyzer
parameter_list|)
block|{
name|this
operator|.
name|searcher
operator|=
name|indexSearcher
expr_stmt|;
comment|//TODO: make non nullable
name|this
operator|.
name|indexAnalyzer
operator|=
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|indexAnalyzer
argument_list|,
literal|"indexAnalyzer is required"
operator|+
literal|" (even if in some circumstances it isn't used)"
argument_list|)
expr_stmt|;
block|}
DECL|method|setHandleMultiTermQuery
specifier|public
name|void
name|setHandleMultiTermQuery
parameter_list|(
name|boolean
name|handleMtq
parameter_list|)
block|{
name|this
operator|.
name|defaultHandleMtq
operator|=
name|handleMtq
expr_stmt|;
block|}
DECL|method|setHighlightPhrasesStrictly
specifier|public
name|void
name|setHighlightPhrasesStrictly
parameter_list|(
name|boolean
name|highlightPhrasesStrictly
parameter_list|)
block|{
name|this
operator|.
name|defaultHighlightPhrasesStrictly
operator|=
name|highlightPhrasesStrictly
expr_stmt|;
block|}
DECL|method|setMaxLength
specifier|public
name|void
name|setMaxLength
parameter_list|(
name|int
name|maxLength
parameter_list|)
block|{
if|if
condition|(
name|maxLength
operator|<
literal|0
operator|||
name|maxLength
operator|==
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
comment|// two reasons: no overflow problems in BreakIterator.preceding(offset+1),
comment|// our sentinel in the offsets queue uses this value to terminate.
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"maxLength must be< Integer.MAX_VALUE"
argument_list|)
throw|;
block|}
name|this
operator|.
name|maxLength
operator|=
name|maxLength
expr_stmt|;
block|}
DECL|method|setBreakIterator
specifier|public
name|void
name|setBreakIterator
parameter_list|(
name|Supplier
argument_list|<
name|BreakIterator
argument_list|>
name|breakIterator
parameter_list|)
block|{
name|this
operator|.
name|defaultBreakIterator
operator|=
name|breakIterator
expr_stmt|;
block|}
DECL|method|setScorer
specifier|public
name|void
name|setScorer
parameter_list|(
name|PassageScorer
name|scorer
parameter_list|)
block|{
name|this
operator|.
name|defaultScorer
operator|=
name|scorer
expr_stmt|;
block|}
DECL|method|setFormatter
specifier|public
name|void
name|setFormatter
parameter_list|(
name|PassageFormatter
name|formatter
parameter_list|)
block|{
name|this
operator|.
name|defaultFormatter
operator|=
name|formatter
expr_stmt|;
block|}
DECL|method|setMaxNoHighlightPassages
specifier|public
name|void
name|setMaxNoHighlightPassages
parameter_list|(
name|int
name|defaultMaxNoHighlightPassages
parameter_list|)
block|{
name|this
operator|.
name|defaultMaxNoHighlightPassages
operator|=
name|defaultMaxNoHighlightPassages
expr_stmt|;
block|}
DECL|method|setCacheFieldValCharsThreshold
specifier|public
name|void
name|setCacheFieldValCharsThreshold
parameter_list|(
name|int
name|cacheFieldValCharsThreshold
parameter_list|)
block|{
name|this
operator|.
name|cacheFieldValCharsThreshold
operator|=
name|cacheFieldValCharsThreshold
expr_stmt|;
block|}
comment|/**    * Returns whether {@link MultiTermQuery} derivatives will be highlighted.  By default it's enabled.  MTQ    * highlighting can be expensive, particularly when using offsets in postings.    */
DECL|method|shouldHandleMultiTermQuery
specifier|protected
name|boolean
name|shouldHandleMultiTermQuery
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
name|defaultHandleMtq
return|;
block|}
comment|/**    * Returns whether position sensitive queries (e.g. phrases and {@link SpanQuery}ies)    * should be highlighted strictly based on query matches (slower)    * versus any/all occurrences of the underlying terms.  By default it's enabled, but there's no overhead if such    * queries aren't used.    */
DECL|method|shouldHighlightPhrasesStrictly
specifier|protected
name|boolean
name|shouldHighlightPhrasesStrictly
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
name|defaultHighlightPhrasesStrictly
return|;
block|}
comment|/**    * The maximum content size to process.  Content will be truncated to this size before highlighting. Typically    * snippets closer to the beginning of the document better summarize its content.    */
DECL|method|getMaxLength
specifier|public
name|int
name|getMaxLength
parameter_list|()
block|{
return|return
name|maxLength
return|;
block|}
comment|/**    * Returns the {@link BreakIterator} to use for    * dividing text into passages.  This returns    * {@link BreakIterator#getSentenceInstance(Locale)} by default;    * subclasses can override to customize.    *<p>    * Note: this highlighter will call    * {@link BreakIterator#preceding(int)} and {@link BreakIterator#next()} many times on it.    * The default generic JDK implementation of {@code preceding} performs poorly.    */
DECL|method|getBreakIterator
specifier|protected
name|BreakIterator
name|getBreakIterator
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
name|defaultBreakIterator
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Returns the {@link PassageScorer} to use for    * ranking passages.  This    * returns a new {@code PassageScorer} by default;    * subclasses can override to customize.    */
DECL|method|getScorer
specifier|protected
name|PassageScorer
name|getScorer
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
name|defaultScorer
return|;
block|}
comment|/**    * Returns the {@link PassageFormatter} to use for    * formatting passages into highlighted snippets.  This    * returns a new {@code PassageFormatter} by default;    * subclasses can override to customize.    */
DECL|method|getFormatter
specifier|protected
name|PassageFormatter
name|getFormatter
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
name|defaultFormatter
return|;
block|}
comment|/**    * Returns the number of leading passages (as delineated by the {@link BreakIterator}) when no    * highlights could be found.  If it's less than 0 (the default) then this defaults to the {@code maxPassages}    * parameter given for each request.  If this is 0 then the resulting highlight is null (not formatted).    */
DECL|method|getMaxNoHighlightPassages
specifier|protected
name|int
name|getMaxNoHighlightPassages
parameter_list|(
name|String
name|field
parameter_list|)
block|{
return|return
name|defaultMaxNoHighlightPassages
return|;
block|}
comment|/**    * Limits the amount of field value pre-fetching until this threshold is passed.  The highlighter    * internally highlights in batches of documents sized on the sum field value length (in chars) of the fields    * to be highlighted (bounded by {@link #getMaxLength()} for each field).  By setting this to 0, you can force    * documents to be fetched and highlighted one at a time, which you usually shouldn't do.    * The default is 524288 chars which translates to about a megabyte.  However, note    * that the highlighter sometimes ignores this and highlights one document at a time (without caching a    * bunch of documents in advance) when it can detect there's no point in it -- such as when all fields will be    * highlighted via re-analysis as one example.    */
DECL|method|getCacheFieldValCharsThreshold
specifier|public
name|int
name|getCacheFieldValCharsThreshold
parameter_list|()
block|{
comment|// question: should we size by bytes instead?
return|return
name|cacheFieldValCharsThreshold
return|;
block|}
comment|/**    * ... as passed in from constructor.    */
DECL|method|getIndexSearcher
specifier|public
name|IndexSearcher
name|getIndexSearcher
parameter_list|()
block|{
return|return
name|searcher
return|;
block|}
comment|/**    * ... as passed in from constructor.    */
DECL|method|getIndexAnalyzer
specifier|public
name|Analyzer
name|getIndexAnalyzer
parameter_list|()
block|{
return|return
name|indexAnalyzer
return|;
block|}
comment|/**    * Source of term offsets; essential for highlighting.    */
DECL|enum|OffsetSource
specifier|public
enum|enum
name|OffsetSource
block|{
DECL|enum constant|POSTINGS
DECL|enum constant|TERM_VECTORS
DECL|enum constant|ANALYSIS
DECL|enum constant|POSTINGS_WITH_TERM_VECTORS
DECL|enum constant|NONE_NEEDED
name|POSTINGS
block|,
name|TERM_VECTORS
block|,
name|ANALYSIS
block|,
name|POSTINGS_WITH_TERM_VECTORS
block|,
name|NONE_NEEDED
block|}
comment|/**    * Determine the offset source for the specified field.  The default algorithm is as follows:    *<ol>    *<li>This calls {@link #getFieldInfo(String)}. Note this returns null if there is no searcher or if the    * field isn't found there.</li>    *<li> If there's a field info it has    * {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS} then {@link OffsetSource#POSTINGS} is    * returned.</li>    *<li>If there's a field info and {@link FieldInfo#hasVectors()} then {@link OffsetSource#TERM_VECTORS} is    * returned (note we can't check here if the TV has offsets; if there isn't then an exception will get thrown    * down the line).</li>    *<li>Fall-back: {@link OffsetSource#ANALYSIS} is returned.</li>    *</ol>    *<p>    * Note that the highlighter sometimes switches to something else based on the query, such as if you have    * {@link OffsetSource#POSTINGS_WITH_TERM_VECTORS} but in fact don't need term vectors.    */
DECL|method|getOffsetSource
specifier|protected
name|OffsetSource
name|getOffsetSource
parameter_list|(
name|String
name|field
parameter_list|)
block|{
name|FieldInfo
name|fieldInfo
init|=
name|getFieldInfo
argument_list|(
name|field
argument_list|)
decl_stmt|;
if|if
condition|(
name|fieldInfo
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|fieldInfo
operator|.
name|getIndexOptions
argument_list|()
operator|==
name|IndexOptions
operator|.
name|DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS
condition|)
block|{
return|return
name|fieldInfo
operator|.
name|hasVectors
argument_list|()
condition|?
name|OffsetSource
operator|.
name|POSTINGS_WITH_TERM_VECTORS
else|:
name|OffsetSource
operator|.
name|POSTINGS
return|;
block|}
if|if
condition|(
name|fieldInfo
operator|.
name|hasVectors
argument_list|()
condition|)
block|{
comment|// unfortunately we can't also check if the TV has offsets
return|return
name|OffsetSource
operator|.
name|TERM_VECTORS
return|;
block|}
block|}
return|return
name|OffsetSource
operator|.
name|ANALYSIS
return|;
block|}
comment|/**    * Called by the default implementation of {@link #getOffsetSource(String)}.    * If there is no searcher then we simply always return null.    */
DECL|method|getFieldInfo
specifier|protected
name|FieldInfo
name|getFieldInfo
parameter_list|(
name|String
name|field
parameter_list|)
block|{
if|if
condition|(
name|searcher
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Need thread-safety for lazy-init but lets avoid 'synchronized' by using double-check locking idiom
name|FieldInfos
name|fieldInfos
init|=
name|this
operator|.
name|fieldInfos
decl_stmt|;
comment|// note: it's volatile; read once
if|if
condition|(
name|fieldInfos
operator|==
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
name|fieldInfos
operator|=
name|this
operator|.
name|fieldInfos
expr_stmt|;
if|if
condition|(
name|fieldInfos
operator|==
literal|null
condition|)
block|{
name|fieldInfos
operator|=
name|MultiFields
operator|.
name|getMergedFieldInfos
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|fieldInfos
operator|=
name|fieldInfos
expr_stmt|;
block|}
block|}
block|}
return|return
name|fieldInfos
operator|.
name|fieldInfo
argument_list|(
name|field
argument_list|)
return|;
block|}
comment|/**    * Highlights the top passages from a single field.    *    * @param field   field name to highlight.    *                Must have a stored string value and also be indexed with offsets.    * @param query   query to highlight.    * @param topDocs TopDocs containing the summary result documents to highlight.    * @return Array of formatted snippets corresponding to the documents in<code>topDocs</code>.    * If no highlights were found for a document, the    * first sentence for the field will be returned.    * @throws IOException              if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without    *                                  {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlight
specifier|public
name|String
index|[]
name|highlight
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|highlight
argument_list|(
name|field
argument_list|,
name|query
argument_list|,
name|topDocs
argument_list|,
literal|1
argument_list|)
return|;
block|}
comment|/**    * Highlights the top-N passages from a single field.    *    * @param field       field name to highlight. Must have a stored string value.    * @param query       query to highlight.    * @param topDocs     TopDocs containing the summary result documents to highlight.    * @param maxPassages The maximum number of top-N ranked passages used to    *                    form the highlighted snippets.    * @return Array of formatted snippets corresponding to the documents in<code>topDocs</code>.    * If no highlights were found for a document, the    * first {@code maxPassages} sentences from the    * field will be returned.    * @throws IOException              if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without    *                                  {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlight
specifier|public
name|String
index|[]
name|highlight
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|,
name|int
name|maxPassages
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|res
init|=
name|highlightFields
argument_list|(
operator|new
name|String
index|[]
block|{
name|field
block|}
argument_list|,
name|query
argument_list|,
name|topDocs
argument_list|,
operator|new
name|int
index|[]
block|{
name|maxPassages
block|}
argument_list|)
decl_stmt|;
return|return
name|res
operator|.
name|get
argument_list|(
name|field
argument_list|)
return|;
block|}
comment|/**    * Highlights the top passages from multiple fields.    *<p>    * Conceptually, this behaves as a more efficient form of:    *<pre class="prettyprint">    * Map m = new HashMap();    * for (String field : fields) {    * m.put(field, highlight(field, query, topDocs));    * }    * return m;    *</pre>    *    * @param fields  field names to highlight. Must have a stored string value.    * @param query   query to highlight.    * @param topDocs TopDocs containing the summary result documents to highlight.    * @return Map keyed on field name, containing the array of formatted snippets    * corresponding to the documents in<code>topDocs</code>.    * If no highlights were found for a document, the    * first sentence from the field will be returned.    * @throws IOException              if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without    *                                  {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFields
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|highlightFields
parameter_list|(
name|String
index|[]
name|fields
parameter_list|,
name|Query
name|query
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|maxPassages
index|[]
init|=
operator|new
name|int
index|[
name|fields
operator|.
name|length
index|]
decl_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|maxPassages
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
name|highlightFields
argument_list|(
name|fields
argument_list|,
name|query
argument_list|,
name|topDocs
argument_list|,
name|maxPassages
argument_list|)
return|;
block|}
comment|/**    * Highlights the top-N passages from multiple fields.    *<p>    * Conceptually, this behaves as a more efficient form of:    *<pre class="prettyprint">    * Map m = new HashMap();    * for (String field : fields) {    * m.put(field, highlight(field, query, topDocs, maxPassages));    * }    * return m;    *</pre>    *    * @param fields      field names to highlight. Must have a stored string value.    * @param query       query to highlight.    * @param topDocs     TopDocs containing the summary result documents to highlight.    * @param maxPassages The maximum number of top-N ranked passages per-field used to    *                    form the highlighted snippets.    * @return Map keyed on field name, containing the array of formatted snippets    * corresponding to the documents in<code>topDocs</code>.    * If no highlights were found for a document, the    * first {@code maxPassages} sentences from the    * field will be returned.    * @throws IOException              if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without    *                                  {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFields
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|highlightFields
parameter_list|(
name|String
index|[]
name|fields
parameter_list|,
name|Query
name|query
parameter_list|,
name|TopDocs
name|topDocs
parameter_list|,
name|int
index|[]
name|maxPassages
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|ScoreDoc
name|scoreDocs
index|[]
init|=
name|topDocs
operator|.
name|scoreDocs
decl_stmt|;
name|int
name|docids
index|[]
init|=
operator|new
name|int
index|[
name|scoreDocs
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|docids
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|docids
index|[
name|i
index|]
operator|=
name|scoreDocs
index|[
name|i
index|]
operator|.
name|doc
expr_stmt|;
block|}
return|return
name|highlightFields
argument_list|(
name|fields
argument_list|,
name|query
argument_list|,
name|docids
argument_list|,
name|maxPassages
argument_list|)
return|;
block|}
comment|/**    * Highlights the top-N passages from multiple fields,    * for the provided int[] docids.    *    * @param fieldsIn      field names to highlight. Must have a stored string value.    * @param query         query to highlight.    * @param docidsIn      containing the document IDs to highlight.    * @param maxPassagesIn The maximum number of top-N ranked passages per-field used to    *                      form the highlighted snippets.    * @return Map keyed on field name, containing the array of formatted snippets    * corresponding to the documents in<code>docidsIn</code>.    * If no highlights were found for a document, the    * first {@code maxPassages} from the field will    * be returned.    * @throws IOException              if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without    *                                  {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFields
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|highlightFields
parameter_list|(
name|String
index|[]
name|fieldsIn
parameter_list|,
name|Query
name|query
parameter_list|,
name|int
index|[]
name|docidsIn
parameter_list|,
name|int
index|[]
name|maxPassagesIn
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
index|[]
argument_list|>
name|snippets
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Object
index|[]
argument_list|>
name|ent
range|:
name|highlightFieldsAsObjects
argument_list|(
name|fieldsIn
argument_list|,
name|query
argument_list|,
name|docidsIn
argument_list|,
name|maxPassagesIn
argument_list|)
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Object
index|[]
name|snippetObjects
init|=
name|ent
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|String
index|[]
name|snippetStrings
init|=
operator|new
name|String
index|[
name|snippetObjects
operator|.
name|length
index|]
decl_stmt|;
name|snippets
operator|.
name|put
argument_list|(
name|ent
operator|.
name|getKey
argument_list|()
argument_list|,
name|snippetStrings
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|snippetObjects
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Object
name|snippet
init|=
name|snippetObjects
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|snippet
operator|!=
literal|null
condition|)
block|{
name|snippetStrings
index|[
name|i
index|]
operator|=
name|snippet
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
block|}
block|}
return|return
name|snippets
return|;
block|}
comment|/**    * Expert: highlights the top-N passages from multiple fields,    * for the provided int[] docids, to custom Object as    * returned by the {@link PassageFormatter}.  Use    * this API to render to something other than String.    *    * @param fieldsIn      field names to highlight. Must have a stored string value.    * @param query         query to highlight.    * @param docIdsIn      containing the document IDs to highlight.    * @param maxPassagesIn The maximum number of top-N ranked passages per-field used to    *                      form the highlighted snippets.    * @return Map keyed on field name, containing the array of formatted snippets    * corresponding to the documents in<code>docIdsIn</code>.    * If no highlights were found for a document, the    * first {@code maxPassages} from the field will    * be returned.    * @throws IOException              if an I/O error occurred during processing    * @throws IllegalArgumentException if<code>field</code> was indexed without    *                                  {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}    */
DECL|method|highlightFieldsAsObjects
specifier|protected
name|Map
argument_list|<
name|String
argument_list|,
name|Object
index|[]
argument_list|>
name|highlightFieldsAsObjects
parameter_list|(
name|String
index|[]
name|fieldsIn
parameter_list|,
name|Query
name|query
parameter_list|,
name|int
index|[]
name|docIdsIn
parameter_list|,
name|int
index|[]
name|maxPassagesIn
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fieldsIn
operator|.
name|length
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"fieldsIn must not be empty"
argument_list|)
throw|;
block|}
if|if
condition|(
name|fieldsIn
operator|.
name|length
operator|!=
name|maxPassagesIn
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"invalid number of maxPassagesIn"
argument_list|)
throw|;
block|}
if|if
condition|(
name|searcher
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"This method requires that an indexSearcher was passed in the "
operator|+
literal|"constructor.  Perhaps you mean to call highlightWithoutSearcher?"
argument_list|)
throw|;
block|}
comment|// Sort docs& fields for sequential i/o
comment|// Sort doc IDs w/ index to original order: (copy input arrays since we sort in-place)
name|int
index|[]
name|docIds
init|=
operator|new
name|int
index|[
name|docIdsIn
operator|.
name|length
index|]
decl_stmt|;
name|int
index|[]
name|docInIndexes
init|=
operator|new
name|int
index|[
name|docIds
operator|.
name|length
index|]
decl_stmt|;
comment|// fill in ascending order; points into docIdsIn[]
name|copyAndSortDocIdsWithIndex
argument_list|(
name|docIdsIn
argument_list|,
name|docIds
argument_list|,
name|docInIndexes
argument_list|)
expr_stmt|;
comment|// latter 2 are "out" params
comment|// Sort fields w/ maxPassages pair: (copy input arrays since we sort in-place)
specifier|final
name|String
name|fields
index|[]
init|=
operator|new
name|String
index|[
name|fieldsIn
operator|.
name|length
index|]
decl_stmt|;
specifier|final
name|int
name|maxPassages
index|[]
init|=
operator|new
name|int
index|[
name|maxPassagesIn
operator|.
name|length
index|]
decl_stmt|;
name|copyAndSortFieldsWithMaxPassages
argument_list|(
name|fieldsIn
argument_list|,
name|maxPassagesIn
argument_list|,
name|fields
argument_list|,
name|maxPassages
argument_list|)
expr_stmt|;
comment|// latter 2 are "out" params
comment|// Init field highlighters (where most of the highlight logic lives, and on a per field basis)
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|queryTerms
init|=
name|extractTerms
argument_list|(
name|query
argument_list|)
decl_stmt|;
name|FieldHighlighter
index|[]
name|fieldHighlighters
init|=
operator|new
name|FieldHighlighter
index|[
name|fields
operator|.
name|length
index|]
decl_stmt|;
name|int
name|numTermVectors
init|=
literal|0
decl_stmt|;
name|int
name|numPostings
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|f
init|=
literal|0
init|;
name|f
operator|<
name|fields
operator|.
name|length
condition|;
name|f
operator|++
control|)
block|{
name|FieldHighlighter
name|fieldHighlighter
init|=
name|getFieldHighlighter
argument_list|(
name|fields
index|[
name|f
index|]
argument_list|,
name|query
argument_list|,
name|queryTerms
argument_list|,
name|maxPassages
index|[
name|f
index|]
argument_list|)
decl_stmt|;
name|fieldHighlighters
index|[
name|f
index|]
operator|=
name|fieldHighlighter
expr_stmt|;
switch|switch
condition|(
name|fieldHighlighter
operator|.
name|getOffsetSource
argument_list|()
condition|)
block|{
case|case
name|TERM_VECTORS
case|:
name|numTermVectors
operator|++
expr_stmt|;
break|break;
case|case
name|POSTINGS
case|:
name|numPostings
operator|++
expr_stmt|;
break|break;
case|case
name|POSTINGS_WITH_TERM_VECTORS
case|:
name|numTermVectors
operator|++
expr_stmt|;
name|numPostings
operator|++
expr_stmt|;
break|break;
case|case
name|ANALYSIS
case|:
case|case
name|NONE_NEEDED
case|:
default|default:
comment|//do nothing
break|break;
block|}
block|}
name|int
name|cacheCharsThreshold
init|=
name|calculateOptimalCacheCharsThreshold
argument_list|(
name|numTermVectors
argument_list|,
name|numPostings
argument_list|)
decl_stmt|;
name|IndexReader
name|indexReaderWithTermVecCache
init|=
operator|(
name|numTermVectors
operator|>=
literal|2
operator|)
condition|?
name|TermVectorReusingLeafReader
operator|.
name|wrap
argument_list|(
name|searcher
operator|.
name|getIndexReader
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
comment|// [fieldIdx][docIdInIndex] of highlightDoc result
name|Object
index|[]
index|[]
name|highlightDocsInByField
init|=
operator|new
name|Object
index|[
name|fields
operator|.
name|length
index|]
index|[
name|docIds
operator|.
name|length
index|]
decl_stmt|;
comment|// Highlight in doc batches determined by loadFieldValues (consumes from docIdIter)
name|DocIdSetIterator
name|docIdIter
init|=
name|asDocIdSetIterator
argument_list|(
name|docIds
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|batchDocIdx
init|=
literal|0
init|;
name|batchDocIdx
operator|<
name|docIds
operator|.
name|length
condition|;
control|)
block|{
comment|// Load the field values of the first batch of document(s) (note: commonly all docs are in this batch)
name|List
argument_list|<
name|CharSequence
index|[]
argument_list|>
name|fieldValsByDoc
init|=
name|loadFieldValues
argument_list|(
name|fields
argument_list|,
name|docIdIter
argument_list|,
name|cacheCharsThreshold
argument_list|)
decl_stmt|;
comment|//    the size of the above list is the size of the batch (num of docs in the batch)
comment|// Highlight in per-field order first, then by doc (better I/O pattern)
for|for
control|(
name|int
name|fieldIdx
init|=
literal|0
init|;
name|fieldIdx
operator|<
name|fields
operator|.
name|length
condition|;
name|fieldIdx
operator|++
control|)
block|{
name|Object
index|[]
name|resultByDocIn
init|=
name|highlightDocsInByField
index|[
name|fieldIdx
index|]
decl_stmt|;
comment|//parallel to docIdsIn
name|FieldHighlighter
name|fieldHighlighter
init|=
name|fieldHighlighters
index|[
name|fieldIdx
index|]
decl_stmt|;
for|for
control|(
name|int
name|docIdx
init|=
name|batchDocIdx
init|;
name|docIdx
operator|-
name|batchDocIdx
operator|<
name|fieldValsByDoc
operator|.
name|size
argument_list|()
condition|;
name|docIdx
operator|++
control|)
block|{
name|int
name|docId
init|=
name|docIds
index|[
name|docIdx
index|]
decl_stmt|;
comment|//sorted order
name|CharSequence
name|content
init|=
name|fieldValsByDoc
operator|.
name|get
argument_list|(
name|docIdx
operator|-
name|batchDocIdx
argument_list|)
index|[
name|fieldIdx
index|]
decl_stmt|;
if|if
condition|(
name|content
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|IndexReader
name|indexReader
init|=
operator|(
name|fieldHighlighter
operator|.
name|getOffsetSource
argument_list|()
operator|==
name|OffsetSource
operator|.
name|TERM_VECTORS
operator|&&
name|indexReaderWithTermVecCache
operator|!=
literal|null
operator|)
condition|?
name|indexReaderWithTermVecCache
else|:
name|searcher
operator|.
name|getIndexReader
argument_list|()
decl_stmt|;
name|int
name|docInIndex
init|=
name|docInIndexes
index|[
name|docIdx
index|]
decl_stmt|;
comment|//original input order
assert|assert
name|resultByDocIn
index|[
name|docInIndex
index|]
operator|==
literal|null
assert|;
name|resultByDocIn
index|[
name|docInIndex
index|]
operator|=
name|fieldHighlighter
operator|.
name|highlightFieldForDoc
argument_list|(
name|indexReader
argument_list|,
name|docId
argument_list|,
name|content
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|batchDocIdx
operator|+=
name|fieldValsByDoc
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
assert|assert
name|docIdIter
operator|.
name|docID
argument_list|()
operator|==
name|DocIdSetIterator
operator|.
name|NO_MORE_DOCS
operator|||
name|docIdIter
operator|.
name|nextDoc
argument_list|()
operator|==
name|DocIdSetIterator
operator|.
name|NO_MORE_DOCS
assert|;
comment|// TODO reconsider the return type; since this is an "advanced" method, lets not return a Map?  Notice the only
comment|//    caller simply iterates it to build another structure.
comment|// field -> object highlights parallel to docIdsIn
name|Map
argument_list|<
name|String
argument_list|,
name|Object
index|[]
argument_list|>
name|resultMap
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|fields
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|f
init|=
literal|0
init|;
name|f
operator|<
name|fields
operator|.
name|length
condition|;
name|f
operator|++
control|)
block|{
name|resultMap
operator|.
name|put
argument_list|(
name|fields
index|[
name|f
index|]
argument_list|,
name|highlightDocsInByField
index|[
name|f
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|resultMap
return|;
block|}
comment|/**    * When cacheCharsThreshold is 0, loadFieldValues() only fetches one document at a time.  We override it to be 0    * in two circumstances:    */
DECL|method|calculateOptimalCacheCharsThreshold
specifier|private
name|int
name|calculateOptimalCacheCharsThreshold
parameter_list|(
name|int
name|numTermVectors
parameter_list|,
name|int
name|numPostings
parameter_list|)
block|{
if|if
condition|(
name|numPostings
operator|==
literal|0
operator|&&
name|numTermVectors
operator|==
literal|0
condition|)
block|{
comment|// (1) When all fields are ANALYSIS there's no point in caching a batch of documents
comment|// because no other info on disk is needed to highlight it.
return|return
literal|0
return|;
block|}
elseif|else
if|if
condition|(
name|numTermVectors
operator|>=
literal|2
condition|)
block|{
comment|// (2) When two or more fields have term vectors, given the field-then-doc algorithm, the underlying term
comment|// vectors will be fetched in a terrible access pattern unless we highlight a doc at a time and use a special
comment|// current-doc TV cache.  So we do that.  Hopefully one day TVs will be improved to make this pointless.
return|return
literal|0
return|;
block|}
else|else
block|{
return|return
name|getCacheFieldValCharsThreshold
argument_list|()
return|;
block|}
block|}
DECL|method|copyAndSortFieldsWithMaxPassages
specifier|private
name|void
name|copyAndSortFieldsWithMaxPassages
parameter_list|(
name|String
index|[]
name|fieldsIn
parameter_list|,
name|int
index|[]
name|maxPassagesIn
parameter_list|,
specifier|final
name|String
index|[]
name|fields
parameter_list|,
specifier|final
name|int
index|[]
name|maxPassages
parameter_list|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|fieldsIn
argument_list|,
literal|0
argument_list|,
name|fields
argument_list|,
literal|0
argument_list|,
name|fieldsIn
operator|.
name|length
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|maxPassagesIn
argument_list|,
literal|0
argument_list|,
name|maxPassages
argument_list|,
literal|0
argument_list|,
name|maxPassagesIn
operator|.
name|length
argument_list|)
expr_stmt|;
operator|new
name|InPlaceMergeSorter
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|void
name|swap
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
name|String
name|tmp
init|=
name|fields
index|[
name|i
index|]
decl_stmt|;
name|fields
index|[
name|i
index|]
operator|=
name|fields
index|[
name|j
index|]
expr_stmt|;
name|fields
index|[
name|j
index|]
operator|=
name|tmp
expr_stmt|;
name|int
name|tmp2
init|=
name|maxPassages
index|[
name|i
index|]
decl_stmt|;
name|maxPassages
index|[
name|i
index|]
operator|=
name|maxPassages
index|[
name|j
index|]
expr_stmt|;
name|maxPassages
index|[
name|j
index|]
operator|=
name|tmp2
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|compare
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
return|return
name|fields
index|[
name|i
index|]
operator|.
name|compareTo
argument_list|(
name|fields
index|[
name|j
index|]
argument_list|)
return|;
block|}
block|}
operator|.
name|sort
argument_list|(
literal|0
argument_list|,
name|fields
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
DECL|method|copyAndSortDocIdsWithIndex
specifier|private
name|void
name|copyAndSortDocIdsWithIndex
parameter_list|(
name|int
index|[]
name|docIdsIn
parameter_list|,
specifier|final
name|int
index|[]
name|docIds
parameter_list|,
specifier|final
name|int
index|[]
name|docInIndexes
parameter_list|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|docIdsIn
argument_list|,
literal|0
argument_list|,
name|docIds
argument_list|,
literal|0
argument_list|,
name|docIdsIn
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|docInIndexes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|docInIndexes
index|[
name|i
index|]
operator|=
name|i
expr_stmt|;
block|}
operator|new
name|InPlaceMergeSorter
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|void
name|swap
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
name|int
name|tmp
init|=
name|docIds
index|[
name|i
index|]
decl_stmt|;
name|docIds
index|[
name|i
index|]
operator|=
name|docIds
index|[
name|j
index|]
expr_stmt|;
name|docIds
index|[
name|j
index|]
operator|=
name|tmp
expr_stmt|;
name|tmp
operator|=
name|docInIndexes
index|[
name|i
index|]
expr_stmt|;
name|docInIndexes
index|[
name|i
index|]
operator|=
name|docInIndexes
index|[
name|j
index|]
expr_stmt|;
name|docInIndexes
index|[
name|j
index|]
operator|=
name|tmp
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|int
name|compare
parameter_list|(
name|int
name|i
parameter_list|,
name|int
name|j
parameter_list|)
block|{
return|return
name|Integer
operator|.
name|compare
argument_list|(
name|docIds
index|[
name|i
index|]
argument_list|,
name|docIds
index|[
name|j
index|]
argument_list|)
return|;
block|}
block|}
operator|.
name|sort
argument_list|(
literal|0
argument_list|,
name|docIds
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
comment|/**    * Highlights text passed as a parameter.  This requires the {@link IndexSearcher} provided to this highlighter is    * null.  This use-case is more rare.  Naturally, the mode of operation will be {@link OffsetSource#ANALYSIS}.    * The result of this method is whatever the {@link PassageFormatter} returns.  For the {@link    * DefaultPassageFormatter} and assuming {@code content} has non-zero length, the result will be a non-null    * string -- so it's safe to call {@link Object#toString()} on it in that case.    *    * @param field       field name to highlight (as found in the query).    * @param query       query to highlight.    * @param content     text to highlight.    * @param maxPassages The maximum number of top-N ranked passages used to    *                    form the highlighted snippets.    * @return result of the {@link PassageFormatter} -- probably a String.  Might be null.    * @throws IOException if an I/O error occurred during processing    */
comment|//TODO make content a List? and return a List? and ensure getEmptyHighlight is never invoked multiple times?
DECL|method|highlightWithoutSearcher
specifier|public
name|Object
name|highlightWithoutSearcher
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|String
name|content
parameter_list|,
name|int
name|maxPassages
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|searcher
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"highlightWithoutSearcher should only be called on a "
operator|+
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" without an IndexSearcher."
argument_list|)
throw|;
block|}
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|content
argument_list|,
literal|"content is required"
argument_list|)
expr_stmt|;
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|queryTerms
init|=
name|extractTerms
argument_list|(
name|query
argument_list|)
decl_stmt|;
return|return
name|getFieldHighlighter
argument_list|(
name|field
argument_list|,
name|query
argument_list|,
name|queryTerms
argument_list|,
name|maxPassages
argument_list|)
operator|.
name|highlightFieldForDoc
argument_list|(
literal|null
argument_list|,
operator|-
literal|1
argument_list|,
name|content
argument_list|)
return|;
block|}
DECL|method|getFieldHighlighter
specifier|protected
name|FieldHighlighter
name|getFieldHighlighter
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|allTerms
parameter_list|,
name|int
name|maxPassages
parameter_list|)
block|{
return|return
operator|new
name|FieldHighlighter
argument_list|(
name|field
argument_list|,
name|getOffsetStrategy
argument_list|(
name|field
argument_list|,
name|query
argument_list|,
name|allTerms
argument_list|)
argument_list|,
operator|new
name|SplittingBreakIterator
argument_list|(
name|getBreakIterator
argument_list|(
name|field
argument_list|)
argument_list|,
name|UnifiedHighlighter
operator|.
name|MULTIVAL_SEP_CHAR
argument_list|)
argument_list|,
name|getScorer
argument_list|(
name|field
argument_list|)
argument_list|,
name|maxPassages
argument_list|,
name|getMaxNoHighlightPassages
argument_list|(
name|field
argument_list|)
argument_list|,
name|getFormatter
argument_list|(
name|field
argument_list|)
argument_list|)
return|;
block|}
DECL|method|getOffsetStrategy
specifier|protected
name|FieldOffsetStrategy
name|getOffsetStrategy
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|allTerms
parameter_list|)
block|{
name|EnumSet
argument_list|<
name|HighlightFlag
argument_list|>
name|highlightFlags
init|=
name|getFlags
argument_list|(
name|field
argument_list|)
decl_stmt|;
name|BytesRef
index|[]
name|terms
init|=
name|filterExtractedTerms
argument_list|(
name|field
argument_list|,
name|allTerms
argument_list|)
decl_stmt|;
name|PhraseHelper
name|phraseHelper
init|=
name|getPhraseHelper
argument_list|(
name|field
argument_list|,
name|query
argument_list|,
name|highlightFlags
argument_list|)
decl_stmt|;
name|CharacterRunAutomaton
index|[]
name|automata
init|=
name|getAutomata
argument_list|(
name|field
argument_list|,
name|query
argument_list|,
name|highlightFlags
argument_list|)
decl_stmt|;
name|OffsetSource
name|offsetSource
init|=
name|getOptimizedOffsetSource
argument_list|(
name|field
argument_list|,
name|terms
argument_list|,
name|phraseHelper
argument_list|,
name|automata
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|offsetSource
condition|)
block|{
case|case
name|ANALYSIS
case|:
return|return
operator|new
name|AnalysisOffsetStrategy
argument_list|(
name|field
argument_list|,
name|terms
argument_list|,
name|phraseHelper
argument_list|,
name|automata
argument_list|,
name|getIndexAnalyzer
argument_list|()
argument_list|,
name|this
operator|::
name|preMultiTermQueryRewrite
argument_list|)
return|;
case|case
name|NONE_NEEDED
case|:
return|return
name|NoOpOffsetStrategy
operator|.
name|INSTANCE
return|;
case|case
name|TERM_VECTORS
case|:
return|return
operator|new
name|TermVectorOffsetStrategy
argument_list|(
name|field
argument_list|,
name|terms
argument_list|,
name|phraseHelper
argument_list|,
name|automata
argument_list|)
return|;
case|case
name|POSTINGS
case|:
return|return
operator|new
name|PostingsOffsetStrategy
argument_list|(
name|field
argument_list|,
name|terms
argument_list|,
name|phraseHelper
argument_list|,
name|automata
argument_list|)
return|;
case|case
name|POSTINGS_WITH_TERM_VECTORS
case|:
return|return
operator|new
name|PostingsWithTermVectorsOffsetStrategy
argument_list|(
name|field
argument_list|,
name|terms
argument_list|,
name|phraseHelper
argument_list|,
name|automata
argument_list|)
return|;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unrecognized offset source "
operator|+
name|offsetSource
argument_list|)
throw|;
block|}
block|}
DECL|method|getFlags
specifier|protected
name|EnumSet
argument_list|<
name|HighlightFlag
argument_list|>
name|getFlags
parameter_list|(
name|String
name|field
parameter_list|)
block|{
name|EnumSet
argument_list|<
name|HighlightFlag
argument_list|>
name|highlightFlags
init|=
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|HighlightFlag
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|shouldHandleMultiTermQuery
argument_list|(
name|field
argument_list|)
condition|)
block|{
name|highlightFlags
operator|.
name|add
argument_list|(
name|HighlightFlag
operator|.
name|MULTI_TERM_QUERY
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|shouldHighlightPhrasesStrictly
argument_list|(
name|field
argument_list|)
condition|)
block|{
name|highlightFlags
operator|.
name|add
argument_list|(
name|HighlightFlag
operator|.
name|PHRASES
argument_list|)
expr_stmt|;
block|}
return|return
name|highlightFlags
return|;
block|}
DECL|method|filterExtractedTerms
specifier|protected
name|BytesRef
index|[]
name|filterExtractedTerms
parameter_list|(
name|String
name|field
parameter_list|,
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|queryTerms
parameter_list|)
block|{
comment|// TODO consider requireFieldMatch
name|Term
name|floor
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
literal|""
argument_list|)
decl_stmt|;
name|Term
name|ceiling
init|=
operator|new
name|Term
argument_list|(
name|field
argument_list|,
name|UnicodeUtil
operator|.
name|BIG_TERM
argument_list|)
decl_stmt|;
name|SortedSet
argument_list|<
name|Term
argument_list|>
name|fieldTerms
init|=
name|queryTerms
operator|.
name|subSet
argument_list|(
name|floor
argument_list|,
name|ceiling
argument_list|)
decl_stmt|;
comment|// Strip off the redundant field:
name|BytesRef
index|[]
name|terms
init|=
operator|new
name|BytesRef
index|[
name|fieldTerms
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|int
name|termUpto
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Term
name|term
range|:
name|fieldTerms
control|)
block|{
name|terms
index|[
name|termUpto
operator|++
index|]
operator|=
name|term
operator|.
name|bytes
argument_list|()
expr_stmt|;
block|}
return|return
name|terms
return|;
block|}
DECL|method|getPhraseHelper
specifier|protected
name|PhraseHelper
name|getPhraseHelper
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|EnumSet
argument_list|<
name|HighlightFlag
argument_list|>
name|highlightFlags
parameter_list|)
block|{
name|boolean
name|highlightPhrasesStrictly
init|=
name|highlightFlags
operator|.
name|contains
argument_list|(
name|HighlightFlag
operator|.
name|PHRASES
argument_list|)
decl_stmt|;
name|boolean
name|handleMultiTermQuery
init|=
name|highlightFlags
operator|.
name|contains
argument_list|(
name|HighlightFlag
operator|.
name|MULTI_TERM_QUERY
argument_list|)
decl_stmt|;
return|return
name|highlightPhrasesStrictly
condition|?
operator|new
name|PhraseHelper
argument_list|(
name|query
argument_list|,
name|field
argument_list|,
name|this
operator|::
name|requiresRewrite
argument_list|,
name|this
operator|::
name|preSpanQueryRewrite
argument_list|,
operator|!
name|handleMultiTermQuery
argument_list|)
else|:
name|PhraseHelper
operator|.
name|NONE
return|;
block|}
DECL|method|getAutomata
specifier|protected
name|CharacterRunAutomaton
index|[]
name|getAutomata
parameter_list|(
name|String
name|field
parameter_list|,
name|Query
name|query
parameter_list|,
name|EnumSet
argument_list|<
name|HighlightFlag
argument_list|>
name|highlightFlags
parameter_list|)
block|{
return|return
name|highlightFlags
operator|.
name|contains
argument_list|(
name|HighlightFlag
operator|.
name|MULTI_TERM_QUERY
argument_list|)
condition|?
name|MultiTermHighlighting
operator|.
name|extractAutomata
argument_list|(
name|query
argument_list|,
name|field
argument_list|,
operator|!
name|highlightFlags
operator|.
name|contains
argument_list|(
name|HighlightFlag
operator|.
name|PHRASES
argument_list|)
argument_list|,
name|this
operator|::
name|preMultiTermQueryRewrite
argument_list|)
else|:
name|ZERO_LEN_AUTOMATA_ARRAY
return|;
block|}
DECL|method|getOptimizedOffsetSource
specifier|protected
name|OffsetSource
name|getOptimizedOffsetSource
parameter_list|(
name|String
name|field
parameter_list|,
name|BytesRef
index|[]
name|terms
parameter_list|,
name|PhraseHelper
name|phraseHelper
parameter_list|,
name|CharacterRunAutomaton
index|[]
name|automata
parameter_list|)
block|{
if|if
condition|(
name|terms
operator|.
name|length
operator|==
literal|0
operator|&&
name|automata
operator|.
name|length
operator|==
literal|0
operator|&&
operator|!
name|phraseHelper
operator|.
name|willRewrite
argument_list|()
condition|)
block|{
return|return
name|OffsetSource
operator|.
name|NONE_NEEDED
return|;
comment|//nothing to highlight
block|}
name|OffsetSource
name|offsetSource
init|=
name|getOffsetSource
argument_list|(
name|field
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|offsetSource
condition|)
block|{
case|case
name|POSTINGS
case|:
if|if
condition|(
name|phraseHelper
operator|.
name|willRewrite
argument_list|()
condition|)
block|{
comment|// We can't choose the postings offset source when there is "rewriting" in the strict phrase
comment|// processing (rare but possible). Postings requires knowing all the terms (except wildcards)
comment|// up front.
return|return
name|OffsetSource
operator|.
name|ANALYSIS
return|;
block|}
elseif|else
if|if
condition|(
name|automata
operator|.
name|length
operator|>
literal|0
condition|)
block|{
return|return
name|OffsetSource
operator|.
name|ANALYSIS
return|;
block|}
break|break;
case|case
name|POSTINGS_WITH_TERM_VECTORS
case|:
if|if
condition|(
operator|!
name|phraseHelper
operator|.
name|willRewrite
argument_list|()
operator|&&
name|automata
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return
name|OffsetSource
operator|.
name|POSTINGS
return|;
comment|//We don't need term vectors
block|}
break|break;
case|case
name|ANALYSIS
case|:
case|case
name|TERM_VECTORS
case|:
case|case
name|NONE_NEEDED
case|:
default|default:
comment|//stick with the original offset source
break|break;
block|}
return|return
name|offsetSource
return|;
block|}
comment|/**    * When highlighting phrases accurately, we need to know which {@link SpanQuery}'s need to have    * {@link Query#rewrite(IndexReader)} called on them.  It helps performance to avoid it if it's not needed.    * This method will be invoked on all SpanQuery instances recursively. If you have custom SpanQuery queries then    * override this to check instanceof and provide a definitive answer. If the query isn't your custom one, simply    * return null to have the default rules apply, which govern the ones included in Lucene.    */
DECL|method|requiresRewrite
specifier|protected
name|Boolean
name|requiresRewrite
parameter_list|(
name|SpanQuery
name|spanQuery
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
comment|/**    * When highlighting phrases accurately, we may need to handle custom queries that aren't supported in the    * {@link org.apache.lucene.search.highlight.WeightedSpanTermExtractor} as called by the {@code PhraseHelper}.    * Should custom query types be needed, this method should be overriden to return a collection of queries if appropriate,    * or null if nothing to do. If the query is not custom, simply returning null will allow the default rules to apply.    *    * @param query Query to be highlighted    * @return A Collection of Query object(s) if needs to be rewritten, otherwise null.    */
DECL|method|preSpanQueryRewrite
specifier|protected
name|Collection
argument_list|<
name|Query
argument_list|>
name|preSpanQueryRewrite
parameter_list|(
name|Query
name|query
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
comment|/**    * When dealing with multi term queries / span queries, we may need to handle custom queries that aren't supported    * by the default automata extraction in {@code MultiTermHighlighting}. This can be overridden to return a collection    * of queries if appropriate, or null if nothing to do. If query is not custom, simply returning null will allow the    * default rules to apply.    *    * @param query Query to be highlighted    * @return A Collection of Query object(s) if needst o be rewritten, otherwise null.    */
DECL|method|preMultiTermQueryRewrite
specifier|protected
name|Collection
argument_list|<
name|Query
argument_list|>
name|preMultiTermQueryRewrite
parameter_list|(
name|Query
name|query
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
DECL|method|asDocIdSetIterator
specifier|private
name|DocIdSetIterator
name|asDocIdSetIterator
parameter_list|(
name|int
index|[]
name|sortedDocIds
parameter_list|)
block|{
return|return
operator|new
name|DocIdSetIterator
argument_list|()
block|{
name|int
name|idx
init|=
operator|-
literal|1
decl_stmt|;
annotation|@
name|Override
specifier|public
name|int
name|docID
parameter_list|()
block|{
if|if
condition|(
name|idx
operator|<
literal|0
operator|||
name|idx
operator|>=
name|sortedDocIds
operator|.
name|length
condition|)
block|{
return|return
name|NO_MORE_DOCS
return|;
block|}
return|return
name|sortedDocIds
index|[
name|idx
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|nextDoc
parameter_list|()
throws|throws
name|IOException
block|{
name|idx
operator|++
expr_stmt|;
return|return
name|docID
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|advance
parameter_list|(
name|int
name|target
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|super
operator|.
name|slowAdvance
argument_list|(
name|target
argument_list|)
return|;
comment|// won't be called, so whatever
block|}
annotation|@
name|Override
specifier|public
name|long
name|cost
parameter_list|()
block|{
return|return
name|Math
operator|.
name|max
argument_list|(
literal|0
argument_list|,
name|sortedDocIds
operator|.
name|length
operator|-
operator|(
name|idx
operator|+
literal|1
operator|)
argument_list|)
return|;
comment|// remaining docs
block|}
block|}
return|;
block|}
comment|/**    * Loads the String values for each docId by field to be highlighted.  By default this loads from stored fields    * by the same name as given, but a subclass can change the source.  The returned Strings must be identical to    * what was indexed (at least for postings or term-vectors offset sources).    * This method must load fields for at least one document from the given {@link DocIdSetIterator}    * but need not return all of them; by default the character lengths are summed and this method will return early    * when {@code cacheCharsThreshold} is exceeded.  Specifically if that number is 0, then only one document is    * fetched no matter what.  Values in the array of {@link CharSequence} will be null if no value was found.    */
DECL|method|loadFieldValues
specifier|protected
name|List
argument_list|<
name|CharSequence
index|[]
argument_list|>
name|loadFieldValues
parameter_list|(
name|String
index|[]
name|fields
parameter_list|,
name|DocIdSetIterator
name|docIter
parameter_list|,
name|int
name|cacheCharsThreshold
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|CharSequence
index|[]
argument_list|>
name|docListOfFields
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|cacheCharsThreshold
operator|==
literal|0
condition|?
literal|1
else|:
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
literal|64
argument_list|,
name|docIter
operator|.
name|cost
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|LimitedStoredFieldVisitor
name|visitor
init|=
name|newLimitedStoredFieldsVisitor
argument_list|(
name|fields
argument_list|)
decl_stmt|;
name|int
name|sumChars
init|=
literal|0
decl_stmt|;
do|do
block|{
name|int
name|docId
init|=
name|docIter
operator|.
name|nextDoc
argument_list|()
decl_stmt|;
if|if
condition|(
name|docId
operator|==
name|DocIdSetIterator
operator|.
name|NO_MORE_DOCS
condition|)
block|{
break|break;
block|}
name|visitor
operator|.
name|init
argument_list|()
expr_stmt|;
name|searcher
operator|.
name|doc
argument_list|(
name|docId
argument_list|,
name|visitor
argument_list|)
expr_stmt|;
name|CharSequence
index|[]
name|valuesByField
init|=
name|visitor
operator|.
name|getValuesByField
argument_list|()
decl_stmt|;
name|docListOfFields
operator|.
name|add
argument_list|(
name|valuesByField
argument_list|)
expr_stmt|;
for|for
control|(
name|CharSequence
name|val
range|:
name|valuesByField
control|)
block|{
name|sumChars
operator|+=
operator|(
name|val
operator|==
literal|null
condition|?
literal|0
else|:
name|val
operator|.
name|length
argument_list|()
operator|)
expr_stmt|;
block|}
block|}
do|while
condition|(
name|sumChars
operator|<=
name|cacheCharsThreshold
operator|&&
name|cacheCharsThreshold
operator|!=
literal|0
condition|)
do|;
return|return
name|docListOfFields
return|;
block|}
comment|/**    * @lucene.internal    */
DECL|method|newLimitedStoredFieldsVisitor
specifier|protected
name|LimitedStoredFieldVisitor
name|newLimitedStoredFieldsVisitor
parameter_list|(
name|String
index|[]
name|fields
parameter_list|)
block|{
return|return
operator|new
name|LimitedStoredFieldVisitor
argument_list|(
name|fields
argument_list|,
name|MULTIVAL_SEP_CHAR
argument_list|,
name|getMaxLength
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Fetches stored fields for highlighting. Uses a multi-val separator char and honors a max length to retrieve.    * @lucene.internal    */
DECL|class|LimitedStoredFieldVisitor
specifier|protected
specifier|static
class|class
name|LimitedStoredFieldVisitor
extends|extends
name|StoredFieldVisitor
block|{
DECL|field|fields
specifier|protected
specifier|final
name|String
index|[]
name|fields
decl_stmt|;
DECL|field|valueSeparator
specifier|protected
specifier|final
name|char
name|valueSeparator
decl_stmt|;
DECL|field|maxLength
specifier|protected
specifier|final
name|int
name|maxLength
decl_stmt|;
DECL|field|values
specifier|protected
name|CharSequence
index|[]
name|values
decl_stmt|;
comment|// starts off as String; may become StringBuilder.
DECL|field|currentField
specifier|protected
name|int
name|currentField
decl_stmt|;
DECL|method|LimitedStoredFieldVisitor
specifier|public
name|LimitedStoredFieldVisitor
parameter_list|(
name|String
index|[]
name|fields
parameter_list|,
name|char
name|valueSeparator
parameter_list|,
name|int
name|maxLength
parameter_list|)
block|{
name|this
operator|.
name|fields
operator|=
name|fields
expr_stmt|;
name|this
operator|.
name|valueSeparator
operator|=
name|valueSeparator
expr_stmt|;
name|this
operator|.
name|maxLength
operator|=
name|maxLength
expr_stmt|;
block|}
DECL|method|init
name|void
name|init
parameter_list|()
block|{
name|values
operator|=
operator|new
name|CharSequence
index|[
name|fields
operator|.
name|length
index|]
expr_stmt|;
name|currentField
operator|=
operator|-
literal|1
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|stringField
specifier|public
name|void
name|stringField
parameter_list|(
name|FieldInfo
name|fieldInfo
parameter_list|,
name|byte
index|[]
name|byteValue
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|value
init|=
operator|new
name|String
argument_list|(
name|byteValue
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
argument_list|)
decl_stmt|;
assert|assert
name|currentField
operator|>=
literal|0
assert|;
name|CharSequence
name|curValue
init|=
name|values
index|[
name|currentField
index|]
decl_stmt|;
if|if
condition|(
name|curValue
operator|==
literal|null
condition|)
block|{
comment|//question: if truncate due to maxLength, should we try and avoid keeping the other chars in-memory on
comment|//  the backing char[]?
name|values
index|[
name|currentField
index|]
operator|=
name|value
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|maxLength
argument_list|,
name|value
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|//note: may return 'this'
return|return;
block|}
specifier|final
name|int
name|lengthBudget
init|=
name|maxLength
operator|-
name|curValue
operator|.
name|length
argument_list|()
decl_stmt|;
if|if
condition|(
name|lengthBudget
operator|<=
literal|0
condition|)
block|{
return|return;
block|}
name|StringBuilder
name|curValueBuilder
decl_stmt|;
if|if
condition|(
name|curValue
operator|instanceof
name|StringBuilder
condition|)
block|{
name|curValueBuilder
operator|=
operator|(
name|StringBuilder
operator|)
name|curValue
expr_stmt|;
block|}
else|else
block|{
comment|// upgrade String to StringBuilder. Choose a good initial size.
name|curValueBuilder
operator|=
operator|new
name|StringBuilder
argument_list|(
name|curValue
operator|.
name|length
argument_list|()
operator|+
name|Math
operator|.
name|min
argument_list|(
name|lengthBudget
argument_list|,
name|value
operator|.
name|length
argument_list|()
operator|+
literal|256
argument_list|)
argument_list|)
expr_stmt|;
name|curValueBuilder
operator|.
name|append
argument_list|(
name|curValue
argument_list|)
expr_stmt|;
block|}
name|curValueBuilder
operator|.
name|append
argument_list|(
name|valueSeparator
argument_list|)
expr_stmt|;
name|curValueBuilder
operator|.
name|append
argument_list|(
name|value
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|lengthBudget
operator|-
literal|1
argument_list|,
name|value
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|values
index|[
name|currentField
index|]
operator|=
name|curValueBuilder
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|needsField
specifier|public
name|Status
name|needsField
parameter_list|(
name|FieldInfo
name|fieldInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|currentField
operator|=
name|Arrays
operator|.
name|binarySearch
argument_list|(
name|fields
argument_list|,
name|fieldInfo
operator|.
name|name
argument_list|)
expr_stmt|;
if|if
condition|(
name|currentField
operator|<
literal|0
condition|)
block|{
return|return
name|Status
operator|.
name|NO
return|;
block|}
name|CharSequence
name|curVal
init|=
name|values
index|[
name|currentField
index|]
decl_stmt|;
if|if
condition|(
name|curVal
operator|!=
literal|null
operator|&&
name|curVal
operator|.
name|length
argument_list|()
operator|>=
name|maxLength
condition|)
block|{
return|return
name|fields
operator|.
name|length
operator|==
literal|1
condition|?
name|Status
operator|.
name|STOP
else|:
name|Status
operator|.
name|NO
return|;
block|}
return|return
name|Status
operator|.
name|YES
return|;
block|}
DECL|method|getValuesByField
name|CharSequence
index|[]
name|getValuesByField
parameter_list|()
block|{
return|return
name|this
operator|.
name|values
return|;
block|}
block|}
comment|/**    * Wraps an IndexReader that remembers/caches the last call to {@link LeafReader#getTermVectors(int)} so that    * if the next call has the same ID, then it is reused.  If TV's were column-stride (like doc-values), there would    * be no need for this.    */
DECL|class|TermVectorReusingLeafReader
specifier|private
specifier|static
class|class
name|TermVectorReusingLeafReader
extends|extends
name|FilterLeafReader
block|{
DECL|method|wrap
specifier|static
name|IndexReader
name|wrap
parameter_list|(
name|IndexReader
name|reader
parameter_list|)
throws|throws
name|IOException
block|{
name|LeafReader
index|[]
name|leafReaders
init|=
name|reader
operator|.
name|leaves
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|LeafReaderContext
operator|::
name|reader
argument_list|)
operator|.
name|map
argument_list|(
name|TermVectorReusingLeafReader
operator|::
operator|new
argument_list|)
operator|.
name|toArray
argument_list|(
name|LeafReader
index|[]
operator|::
operator|new
argument_list|)
decl_stmt|;
return|return
operator|new
name|BaseCompositeReader
argument_list|<
name|IndexReader
argument_list|>
argument_list|(
name|leafReaders
argument_list|)
block|{
annotation|@
name|Override
specifier|protected
name|void
name|doClose
parameter_list|()
throws|throws
name|IOException
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
return|;
block|}
DECL|field|lastDocId
specifier|private
name|int
name|lastDocId
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|tvFields
specifier|private
name|Fields
name|tvFields
decl_stmt|;
DECL|method|TermVectorReusingLeafReader
name|TermVectorReusingLeafReader
parameter_list|(
name|LeafReader
name|in
parameter_list|)
block|{
name|super
argument_list|(
name|in
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|getTermVectors
specifier|public
name|Fields
name|getTermVectors
parameter_list|(
name|int
name|docID
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|docID
operator|!=
name|lastDocId
condition|)
block|{
name|lastDocId
operator|=
name|docID
expr_stmt|;
name|tvFields
operator|=
name|in
operator|.
name|getTermVectors
argument_list|(
name|docID
argument_list|)
expr_stmt|;
block|}
return|return
name|tvFields
return|;
block|}
block|}
comment|/**    * Flags for controlling highlighting behavior.    */
DECL|enum|HighlightFlag
specifier|public
enum|enum
name|HighlightFlag
block|{
DECL|enum constant|PHRASES
name|PHRASES
block|,
DECL|enum constant|MULTI_TERM_QUERY
name|MULTI_TERM_QUERY
comment|// TODO: ignoreQueryFields
comment|// TODO: useQueryBoosts
comment|// TODO: avoidMemoryIndexIfPossible
comment|// TODO: preferMemoryIndexForStats
block|}
block|}
end_class

end_unit

