begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.lucene.analysis.pattern
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|pattern
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Tokenizer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|ArrayUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|AttributeFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|automaton
operator|.
name|Automaton
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|automaton
operator|.
name|CharacterRunAutomaton
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|automaton
operator|.
name|Operations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|automaton
operator|.
name|RegExp
import|;
end_import

begin_comment
comment|/**  * This tokenizer uses a Lucene {@link RegExp} or (expert usage) a pre-built determinized {@link Automaton}, to locate tokens.  * The regexp syntax is more limited than {@link PatternTokenizer}, but the tokenization is quite a bit faster.  The provided  * regex should match valid token characters (not token separator characters, like {@code String.split}).  The matching is greedy:  * the longest match at a given start point will be the next token.  Empty string tokens are never produced.  *  * @lucene.experimental  */
end_comment

begin_comment
comment|// TODO: the matcher here is naive and does have N^2 adversarial cases that are unlikely to arise in practice, e.g. if the pattern is
end_comment

begin_comment
comment|// aaaaaaaaaab and the input is aaaaaaaaaaa, the work we do here is N^2 where N is the number of a's.  This is because on failing to match
end_comment

begin_comment
comment|// a token, we skip one character forward and try again.  A better approach would be to compile something like this regexp
end_comment

begin_comment
comment|// instead: .* |<pattern>, because that automaton would not "forget" all the as it had already seen, and would be a single pass
end_comment

begin_comment
comment|// through the input.  I think this is the same thing as Aho/Corasick's algorithm (http://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_string_matching_algorithm).
end_comment

begin_comment
comment|// But we cannot implement this (I think?) until/unless Lucene regexps support sub-group capture, so we could know
end_comment

begin_comment
comment|// which specific characters the pattern matched.  SynonymFilter has this same limitation.
end_comment

begin_class
DECL|class|SimplePatternTokenizer
specifier|public
specifier|final
class|class
name|SimplePatternTokenizer
extends|extends
name|Tokenizer
block|{
DECL|field|termAtt
specifier|private
specifier|final
name|CharTermAttribute
name|termAtt
init|=
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|offsetAtt
specifier|private
specifier|final
name|OffsetAttribute
name|offsetAtt
init|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|runDFA
specifier|private
specifier|final
name|CharacterRunAutomaton
name|runDFA
decl_stmt|;
comment|// TODO: we could likely use a single rolling buffer instead of two separate char buffers here.  We could also use PushBackReader but I
comment|// suspect it's slowish:
DECL|field|pendingChars
specifier|private
name|char
index|[]
name|pendingChars
init|=
operator|new
name|char
index|[
literal|8
index|]
decl_stmt|;
DECL|field|pendingLimit
specifier|private
name|int
name|pendingLimit
decl_stmt|;
DECL|field|pendingUpto
specifier|private
name|int
name|pendingUpto
decl_stmt|;
DECL|field|offset
specifier|private
name|int
name|offset
decl_stmt|;
DECL|field|tokenUpto
specifier|private
name|int
name|tokenUpto
decl_stmt|;
DECL|field|buffer
specifier|private
specifier|final
name|char
index|[]
name|buffer
init|=
operator|new
name|char
index|[
literal|1024
index|]
decl_stmt|;
DECL|field|bufferLimit
specifier|private
name|int
name|bufferLimit
decl_stmt|;
DECL|field|bufferNextRead
specifier|private
name|int
name|bufferNextRead
decl_stmt|;
comment|/** See {@link RegExp} for the accepted syntax. */
DECL|method|SimplePatternTokenizer
specifier|public
name|SimplePatternTokenizer
parameter_list|(
name|String
name|regexp
parameter_list|)
block|{
name|this
argument_list|(
name|DEFAULT_TOKEN_ATTRIBUTE_FACTORY
argument_list|,
name|regexp
argument_list|,
name|Operations
operator|.
name|DEFAULT_MAX_DETERMINIZED_STATES
argument_list|)
expr_stmt|;
block|}
comment|/** Runs a pre-built automaton. */
DECL|method|SimplePatternTokenizer
specifier|public
name|SimplePatternTokenizer
parameter_list|(
name|Automaton
name|dfa
parameter_list|)
block|{
name|this
argument_list|(
name|DEFAULT_TOKEN_ATTRIBUTE_FACTORY
argument_list|,
name|dfa
argument_list|)
expr_stmt|;
block|}
comment|/** See {@link RegExp} for the accepted syntax. */
DECL|method|SimplePatternTokenizer
specifier|public
name|SimplePatternTokenizer
parameter_list|(
name|AttributeFactory
name|factory
parameter_list|,
name|String
name|regexp
parameter_list|,
name|int
name|maxDeterminizedStates
parameter_list|)
block|{
name|this
argument_list|(
name|factory
argument_list|,
operator|new
name|RegExp
argument_list|(
name|regexp
argument_list|)
operator|.
name|toAutomaton
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/** Runs a pre-built automaton. */
DECL|method|SimplePatternTokenizer
specifier|public
name|SimplePatternTokenizer
parameter_list|(
name|AttributeFactory
name|factory
parameter_list|,
name|Automaton
name|dfa
parameter_list|)
block|{
name|super
argument_list|(
name|factory
argument_list|)
expr_stmt|;
comment|// we require user to do this up front because it is a possibly very costly operation, and user may be creating us frequently, not
comment|// realizing this ctor is otherwise trappy
if|if
condition|(
name|dfa
operator|.
name|isDeterministic
argument_list|()
operator|==
literal|false
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"please determinize the incoming automaton first"
argument_list|)
throw|;
block|}
name|runDFA
operator|=
operator|new
name|CharacterRunAutomaton
argument_list|(
name|dfa
argument_list|,
name|Operations
operator|.
name|DEFAULT_MAX_DETERMINIZED_STATES
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|incrementToken
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
name|clearAttributes
argument_list|()
expr_stmt|;
name|tokenUpto
operator|=
literal|0
expr_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|int
name|offsetStart
init|=
name|offset
decl_stmt|;
comment|// The runDFA operates in Unicode space, not UTF16 (java's char):
name|int
name|ch
init|=
name|nextCodePoint
argument_list|()
decl_stmt|;
if|if
condition|(
name|ch
operator|==
operator|-
literal|1
condition|)
block|{
return|return
literal|false
return|;
block|}
name|int
name|state
init|=
name|runDFA
operator|.
name|step
argument_list|(
literal|0
argument_list|,
name|ch
argument_list|)
decl_stmt|;
if|if
condition|(
name|state
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// a token just possibly started; keep scanning to see if the token is accepted:
name|int
name|lastAcceptLength
init|=
operator|-
literal|1
decl_stmt|;
do|do
block|{
if|if
condition|(
name|runDFA
operator|.
name|isAccept
argument_list|(
name|state
argument_list|)
condition|)
block|{
comment|// record that the token matches here, but keep scanning in case a longer match also works (greedy):
name|lastAcceptLength
operator|=
name|tokenUpto
expr_stmt|;
block|}
name|ch
operator|=
name|nextCodePoint
argument_list|()
expr_stmt|;
if|if
condition|(
name|ch
operator|==
operator|-
literal|1
condition|)
block|{
break|break;
block|}
name|state
operator|=
name|runDFA
operator|.
name|step
argument_list|(
name|state
argument_list|,
name|ch
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|state
operator|!=
operator|-
literal|1
condition|)
do|;
if|if
condition|(
name|lastAcceptLength
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// we found a token
name|int
name|extra
init|=
name|tokenUpto
operator|-
name|lastAcceptLength
decl_stmt|;
if|if
condition|(
name|extra
operator|!=
literal|0
condition|)
block|{
name|pushBack
argument_list|(
name|extra
argument_list|)
expr_stmt|;
block|}
name|termAtt
operator|.
name|setLength
argument_list|(
name|lastAcceptLength
argument_list|)
expr_stmt|;
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|correctOffset
argument_list|(
name|offsetStart
argument_list|)
argument_list|,
name|correctOffset
argument_list|(
name|offsetStart
operator|+
name|lastAcceptLength
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
elseif|else
if|if
condition|(
name|ch
operator|==
operator|-
literal|1
condition|)
block|{
return|return
literal|false
return|;
block|}
else|else
block|{
comment|// false alarm: there was no token here; push back all but the first character we scanned
name|pushBack
argument_list|(
name|tokenUpto
operator|-
literal|1
argument_list|)
expr_stmt|;
name|tokenUpto
operator|=
literal|0
expr_stmt|;
block|}
block|}
else|else
block|{
name|tokenUpto
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|end
specifier|public
name|void
name|end
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|end
argument_list|()
expr_stmt|;
specifier|final
name|int
name|ofs
init|=
name|correctOffset
argument_list|(
name|offset
operator|+
name|pendingLimit
operator|-
name|pendingUpto
argument_list|)
decl_stmt|;
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|ofs
argument_list|,
name|ofs
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|reset
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
name|offset
operator|=
literal|0
expr_stmt|;
name|pendingUpto
operator|=
literal|0
expr_stmt|;
name|pendingLimit
operator|=
literal|0
expr_stmt|;
name|tokenUpto
operator|=
literal|0
expr_stmt|;
name|bufferNextRead
operator|=
literal|0
expr_stmt|;
name|bufferLimit
operator|=
literal|0
expr_stmt|;
block|}
comment|/** Pushes back the last {@code count} characters in current token's buffer. */
DECL|method|pushBack
specifier|private
name|void
name|pushBack
parameter_list|(
name|int
name|count
parameter_list|)
block|{
if|if
condition|(
name|pendingLimit
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bufferNextRead
operator|>=
name|count
condition|)
block|{
comment|// optimize common case when the chars we are pushing back are still in the buffer
name|bufferNextRead
operator|-=
name|count
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|count
operator|>
name|pendingChars
operator|.
name|length
condition|)
block|{
name|pendingChars
operator|=
name|ArrayUtil
operator|.
name|grow
argument_list|(
name|pendingChars
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
name|System
operator|.
name|arraycopy
argument_list|(
name|termAtt
operator|.
name|buffer
argument_list|()
argument_list|,
name|tokenUpto
operator|-
name|count
argument_list|,
name|pendingChars
argument_list|,
literal|0
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|pendingLimit
operator|=
name|count
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// we are pushing back what is already in our pending buffer
name|pendingUpto
operator|-=
name|count
expr_stmt|;
assert|assert
name|pendingUpto
operator|>=
literal|0
assert|;
block|}
name|offset
operator|-=
name|count
expr_stmt|;
block|}
DECL|method|appendToToken
specifier|private
name|void
name|appendToToken
parameter_list|(
name|char
name|ch
parameter_list|)
block|{
name|char
index|[]
name|buffer
init|=
name|termAtt
operator|.
name|buffer
argument_list|()
decl_stmt|;
if|if
condition|(
name|tokenUpto
operator|==
name|buffer
operator|.
name|length
condition|)
block|{
name|buffer
operator|=
name|termAtt
operator|.
name|resizeBuffer
argument_list|(
name|tokenUpto
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
name|buffer
index|[
name|tokenUpto
operator|++
index|]
operator|=
name|ch
expr_stmt|;
block|}
DECL|method|nextCodeUnit
specifier|private
name|int
name|nextCodeUnit
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|result
decl_stmt|;
if|if
condition|(
name|pendingUpto
operator|<
name|pendingLimit
condition|)
block|{
name|result
operator|=
name|pendingChars
index|[
name|pendingUpto
operator|++
index|]
expr_stmt|;
if|if
condition|(
name|pendingUpto
operator|==
name|pendingLimit
condition|)
block|{
comment|// We used up the pending buffer
name|pendingUpto
operator|=
literal|0
expr_stmt|;
name|pendingLimit
operator|=
literal|0
expr_stmt|;
block|}
name|appendToToken
argument_list|(
operator|(
name|char
operator|)
name|result
argument_list|)
expr_stmt|;
name|offset
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bufferLimit
operator|==
operator|-
literal|1
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
else|else
block|{
assert|assert
name|bufferNextRead
operator|<=
name|bufferLimit
operator|:
literal|"bufferNextRead="
operator|+
name|bufferNextRead
operator|+
literal|" bufferLimit="
operator|+
name|bufferLimit
assert|;
if|if
condition|(
name|bufferNextRead
operator|==
name|bufferLimit
condition|)
block|{
name|bufferLimit
operator|=
name|input
operator|.
name|read
argument_list|(
name|buffer
argument_list|,
literal|0
argument_list|,
name|buffer
operator|.
name|length
argument_list|)
expr_stmt|;
if|if
condition|(
name|bufferLimit
operator|==
operator|-
literal|1
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
name|bufferNextRead
operator|=
literal|0
expr_stmt|;
block|}
name|result
operator|=
name|buffer
index|[
name|bufferNextRead
operator|++
index|]
expr_stmt|;
name|offset
operator|++
expr_stmt|;
name|appendToToken
argument_list|(
operator|(
name|char
operator|)
name|result
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
DECL|method|nextCodePoint
specifier|private
name|int
name|nextCodePoint
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|ch
init|=
name|nextCodeUnit
argument_list|()
decl_stmt|;
if|if
condition|(
name|ch
operator|==
operator|-
literal|1
condition|)
block|{
return|return
name|ch
return|;
block|}
if|if
condition|(
name|Character
operator|.
name|isHighSurrogate
argument_list|(
operator|(
name|char
operator|)
name|ch
argument_list|)
condition|)
block|{
return|return
name|Character
operator|.
name|toCodePoint
argument_list|(
operator|(
name|char
operator|)
name|ch
argument_list|,
operator|(
name|char
operator|)
name|nextCodeUnit
argument_list|()
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|ch
return|;
block|}
block|}
block|}
end_class

end_unit

