begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.lucene.analysis.wikipedia
package|package
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|wikipedia
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Tokenizer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|util
operator|.
name|BaseTokenStreamFactoryTestCase
import|;
end_import

begin_comment
comment|/**  * Simple tests to ensure the wikipedia tokenizer is working.  */
end_comment

begin_class
DECL|class|TestWikipediaTokenizerFactory
specifier|public
class|class
name|TestWikipediaTokenizerFactory
extends|extends
name|BaseTokenStreamFactoryTestCase
block|{
DECL|field|WIKIPEDIA
specifier|private
specifier|final
name|String
name|WIKIPEDIA
init|=
literal|"Wikipedia"
decl_stmt|;
DECL|field|TOKEN_OUTPUT
specifier|private
specifier|final
name|String
name|TOKEN_OUTPUT
init|=
literal|"tokenOutput"
decl_stmt|;
DECL|field|UNTOKENIZED_TYPES
specifier|private
specifier|final
name|String
name|UNTOKENIZED_TYPES
init|=
literal|"untokenizedTypes"
decl_stmt|;
DECL|method|testTokenizer
specifier|public
name|void
name|testTokenizer
parameter_list|()
throws|throws
name|Exception
block|{
name|String
name|text
init|=
literal|"This is a [[Category:foo]]"
decl_stmt|;
name|Tokenizer
name|tf
init|=
name|tokenizerFactory
argument_list|(
name|WIKIPEDIA
argument_list|)
operator|.
name|create
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|)
decl_stmt|;
name|tf
operator|.
name|setReader
argument_list|(
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
expr_stmt|;
name|assertTokenStreamContents
argument_list|(
name|tf
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"This"
block|,
literal|"is"
block|,
literal|"a"
block|,
literal|"foo"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|5
block|,
literal|8
block|,
literal|21
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|4
block|,
literal|7
block|,
literal|9
block|,
literal|24
block|}
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"<ALPHANUM>"
block|,
literal|"<ALPHANUM>"
block|,
literal|"<ALPHANUM>"
block|,
name|WikipediaTokenizer
operator|.
name|CATEGORY
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|, }
argument_list|,
name|text
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|testTokenizerTokensOnly
specifier|public
name|void
name|testTokenizerTokensOnly
parameter_list|()
throws|throws
name|Exception
block|{
name|String
name|text
init|=
literal|"This is a [[Category:foo]]"
decl_stmt|;
name|Tokenizer
name|tf
init|=
name|tokenizerFactory
argument_list|(
name|WIKIPEDIA
argument_list|,
name|TOKEN_OUTPUT
argument_list|,
operator|new
name|Integer
argument_list|(
name|WikipediaTokenizer
operator|.
name|TOKENS_ONLY
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|)
operator|.
name|create
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|)
decl_stmt|;
name|tf
operator|.
name|setReader
argument_list|(
operator|new
name|StringReader
argument_list|(
name|text
argument_list|)
argument_list|)
expr_stmt|;
name|assertTokenStreamContents
argument_list|(
name|tf
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"This"
block|,
literal|"is"
block|,
literal|"a"
block|,
literal|"foo"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|5
block|,
literal|8
block|,
literal|21
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|4
block|,
literal|7
block|,
literal|9
block|,
literal|24
block|}
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"<ALPHANUM>"
block|,
literal|"<ALPHANUM>"
block|,
literal|"<ALPHANUM>"
block|,
name|WikipediaTokenizer
operator|.
name|CATEGORY
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|, }
argument_list|,
name|text
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|testTokenizerUntokenizedOnly
specifier|public
name|void
name|testTokenizerUntokenizedOnly
parameter_list|()
throws|throws
name|Exception
block|{
name|String
name|test
init|=
literal|"[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]"
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|untoks
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|untoks
operator|.
name|add
argument_list|(
name|WikipediaTokenizer
operator|.
name|CATEGORY
argument_list|)
expr_stmt|;
name|untoks
operator|.
name|add
argument_list|(
name|WikipediaTokenizer
operator|.
name|ITALICS
argument_list|)
expr_stmt|;
name|Tokenizer
name|tf
init|=
name|tokenizerFactory
argument_list|(
name|WIKIPEDIA
argument_list|,
name|TOKEN_OUTPUT
argument_list|,
operator|new
name|Integer
argument_list|(
name|WikipediaTokenizer
operator|.
name|UNTOKENIZED_ONLY
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|,
name|UNTOKENIZED_TYPES
argument_list|,
name|WikipediaTokenizer
operator|.
name|CATEGORY
operator|+
literal|", "
operator|+
name|WikipediaTokenizer
operator|.
name|ITALICS
argument_list|)
operator|.
name|create
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|)
decl_stmt|;
name|tf
operator|.
name|setReader
argument_list|(
operator|new
name|StringReader
argument_list|(
name|test
argument_list|)
argument_list|)
expr_stmt|;
name|assertTokenStreamContents
argument_list|(
name|tf
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a b c d"
block|,
literal|"e f g"
block|,
literal|"link"
block|,
literal|"here"
block|,
literal|"link"
block|,
literal|"there"
block|,
literal|"italics here"
block|,
literal|"something"
block|,
literal|"more italics"
block|,
literal|"h   i   j"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|11
block|,
literal|32
block|,
literal|42
block|,
literal|47
block|,
literal|56
block|,
literal|61
block|,
literal|71
block|,
literal|86
block|,
literal|98
block|,
literal|124
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|18
block|,
literal|37
block|,
literal|46
block|,
literal|51
block|,
literal|60
block|,
literal|66
block|,
literal|83
block|,
literal|95
block|,
literal|110
block|,
literal|133
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|testTokenizerBoth
specifier|public
name|void
name|testTokenizerBoth
parameter_list|()
throws|throws
name|Exception
block|{
name|String
name|test
init|=
literal|"[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]"
decl_stmt|;
name|Tokenizer
name|tf
init|=
name|tokenizerFactory
argument_list|(
name|WIKIPEDIA
argument_list|,
name|TOKEN_OUTPUT
argument_list|,
operator|new
name|Integer
argument_list|(
name|WikipediaTokenizer
operator|.
name|BOTH
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|,
name|UNTOKENIZED_TYPES
argument_list|,
name|WikipediaTokenizer
operator|.
name|CATEGORY
operator|+
literal|", "
operator|+
name|WikipediaTokenizer
operator|.
name|ITALICS
argument_list|)
operator|.
name|create
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|)
decl_stmt|;
name|tf
operator|.
name|setReader
argument_list|(
operator|new
name|StringReader
argument_list|(
name|test
argument_list|)
argument_list|)
expr_stmt|;
name|assertTokenStreamContents
argument_list|(
name|tf
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"a b c d"
block|,
literal|"a"
block|,
literal|"b"
block|,
literal|"c"
block|,
literal|"d"
block|,
literal|"e f g"
block|,
literal|"e"
block|,
literal|"f"
block|,
literal|"g"
block|,
literal|"link"
block|,
literal|"here"
block|,
literal|"link"
block|,
literal|"there"
block|,
literal|"italics here"
block|,
literal|"italics"
block|,
literal|"here"
block|,
literal|"something"
block|,
literal|"more italics"
block|,
literal|"more"
block|,
literal|"italics"
block|,
literal|"h   i   j"
block|,
literal|"h"
block|,
literal|"i"
block|,
literal|"j"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|11
block|,
literal|11
block|,
literal|13
block|,
literal|15
block|,
literal|17
block|,
literal|32
block|,
literal|32
block|,
literal|34
block|,
literal|36
block|,
literal|42
block|,
literal|47
block|,
literal|56
block|,
literal|61
block|,
literal|71
block|,
literal|71
block|,
literal|79
block|,
literal|86
block|,
literal|98
block|,
literal|98
block|,
literal|103
block|,
literal|124
block|,
literal|124
block|,
literal|128
block|,
literal|132
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|18
block|,
literal|12
block|,
literal|14
block|,
literal|16
block|,
literal|18
block|,
literal|37
block|,
literal|33
block|,
literal|35
block|,
literal|37
block|,
literal|46
block|,
literal|51
block|,
literal|60
block|,
literal|66
block|,
literal|83
block|,
literal|78
block|,
literal|83
block|,
literal|95
block|,
literal|110
block|,
literal|102
block|,
literal|110
block|,
literal|133
block|,
literal|125
block|,
literal|129
block|,
literal|133
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|1
block|}
argument_list|)
expr_stmt|;
block|}
comment|/** Test that bogus arguments result in exception */
DECL|method|testBogusArguments
specifier|public
name|void
name|testBogusArguments
parameter_list|()
throws|throws
name|Exception
block|{
name|IllegalArgumentException
name|expected
init|=
name|expectThrows
argument_list|(
name|IllegalArgumentException
operator|.
name|class
argument_list|,
parameter_list|()
lambda|->
block|{
name|tokenizerFactory
argument_list|(
name|WIKIPEDIA
argument_list|,
literal|"bogusArg"
argument_list|,
literal|"bogusValue"
argument_list|)
operator|.
name|create
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|)
expr_stmt|;
block|}
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|expected
operator|.
name|getMessage
argument_list|()
operator|.
name|contains
argument_list|(
literal|"Unknown parameters"
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|testIllegalArguments
specifier|public
name|void
name|testIllegalArguments
parameter_list|()
throws|throws
name|Exception
block|{
name|IllegalArgumentException
name|expected
init|=
name|expectThrows
argument_list|(
name|IllegalArgumentException
operator|.
name|class
argument_list|,
parameter_list|()
lambda|->
block|{
name|Tokenizer
name|tf
init|=
name|tokenizerFactory
argument_list|(
name|WIKIPEDIA
argument_list|,
name|TOKEN_OUTPUT
argument_list|,
literal|"-1"
argument_list|)
operator|.
name|create
argument_list|(
name|newAttributeFactory
argument_list|()
argument_list|)
decl_stmt|;
block|}
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|expected
operator|.
name|getMessage
argument_list|()
operator|.
name|contains
argument_list|(
literal|"tokenOutput must be TOKENS_ONLY, UNTOKENIZED_ONLY or BOTH"
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

