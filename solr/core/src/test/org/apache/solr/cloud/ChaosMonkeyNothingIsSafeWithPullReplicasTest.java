begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.solr.cloud
package|package
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|cloud
package|;
end_package

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|invoke
operator|.
name|MethodHandles
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|LuceneTestCase
operator|.
name|Slow
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|SolrTestCaseJ4
operator|.
name|SuppressObjectReleaseTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|SolrTestCaseJ4
operator|.
name|SuppressSSL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|client
operator|.
name|solrj
operator|.
name|SolrQuery
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|client
operator|.
name|solrj
operator|.
name|impl
operator|.
name|CloudSolrClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|SolrInputDocument
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|cloud
operator|.
name|DocCollection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|cloud
operator|.
name|Replica
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|cloud
operator|.
name|Slice
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|common
operator|.
name|cloud
operator|.
name|ZkStateReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|util
operator|.
name|TestInjection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|solr
operator|.
name|util
operator|.
name|TimeOut
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|AfterClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|BeforeClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|randomizedtesting
operator|.
name|annotations
operator|.
name|ThreadLeakLingering
import|;
end_import

begin_class
annotation|@
name|Slow
annotation|@
name|SuppressSSL
argument_list|(
name|bugUrl
operator|=
literal|"https://issues.apache.org/jira/browse/SOLR-5776"
argument_list|)
annotation|@
name|ThreadLeakLingering
argument_list|(
name|linger
operator|=
literal|60000
argument_list|)
annotation|@
name|SuppressObjectReleaseTracker
argument_list|(
name|bugUrl
operator|=
literal|"Testing purposes"
argument_list|)
DECL|class|ChaosMonkeyNothingIsSafeWithPullReplicasTest
specifier|public
class|class
name|ChaosMonkeyNothingIsSafeWithPullReplicasTest
extends|extends
name|AbstractFullDistribZkTestBase
block|{
DECL|field|FAIL_TOLERANCE
specifier|private
specifier|static
specifier|final
name|int
name|FAIL_TOLERANCE
init|=
literal|100
decl_stmt|;
DECL|field|log
specifier|private
specifier|static
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MethodHandles
operator|.
name|lookup
argument_list|()
operator|.
name|lookupClass
argument_list|()
argument_list|)
decl_stmt|;
DECL|field|RUN_LENGTH
specifier|private
specifier|static
specifier|final
name|Integer
name|RUN_LENGTH
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"solr.tests.cloud.cm.runlength"
argument_list|,
literal|"-1"
argument_list|)
argument_list|)
decl_stmt|;
DECL|field|useTlogReplicas
specifier|private
specifier|final
name|boolean
name|useTlogReplicas
init|=
name|random
argument_list|()
operator|.
name|nextBoolean
argument_list|()
decl_stmt|;
DECL|field|numPullReplicas
specifier|private
specifier|final
name|int
name|numPullReplicas
decl_stmt|;
DECL|field|numRealtimeOrTlogReplicas
specifier|private
specifier|final
name|int
name|numRealtimeOrTlogReplicas
decl_stmt|;
DECL|method|getPullReplicaCount
specifier|protected
name|int
name|getPullReplicaCount
parameter_list|()
block|{
return|return
name|numPullReplicas
return|;
block|}
annotation|@
name|BeforeClass
DECL|method|beforeSuperClass
specifier|public
specifier|static
name|void
name|beforeSuperClass
parameter_list|()
block|{
name|schemaString
operator|=
literal|"schema15.xml"
expr_stmt|;
comment|// we need a string id
if|if
condition|(
name|usually
argument_list|()
condition|)
block|{
name|System
operator|.
name|setProperty
argument_list|(
literal|"solr.autoCommit.maxTime"
argument_list|,
literal|"15000"
argument_list|)
expr_stmt|;
block|}
name|TestInjection
operator|.
name|waitForReplicasInSync
operator|=
literal|null
expr_stmt|;
name|setErrorHook
argument_list|()
expr_stmt|;
block|}
annotation|@
name|AfterClass
DECL|method|afterSuperClass
specifier|public
specifier|static
name|void
name|afterSuperClass
parameter_list|()
block|{
name|System
operator|.
name|clearProperty
argument_list|(
literal|"solr.autoCommit.maxTime"
argument_list|)
expr_stmt|;
name|clearErrorHook
argument_list|()
expr_stmt|;
name|TestInjection
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
DECL|field|fieldNames
specifier|protected
specifier|static
specifier|final
name|String
index|[]
name|fieldNames
init|=
operator|new
name|String
index|[]
block|{
literal|"f_i"
block|,
literal|"f_f"
block|,
literal|"f_d"
block|,
literal|"f_l"
block|,
literal|"f_dt"
block|}
decl_stmt|;
DECL|field|randVals
specifier|protected
specifier|static
specifier|final
name|RandVal
index|[]
name|randVals
init|=
operator|new
name|RandVal
index|[]
block|{
name|rint
block|,
name|rfloat
block|,
name|rdouble
block|,
name|rlong
block|,
name|rdate
block|}
decl_stmt|;
DECL|field|clientSoTimeout
specifier|private
name|int
name|clientSoTimeout
decl_stmt|;
DECL|method|getFieldNames
specifier|public
name|String
index|[]
name|getFieldNames
parameter_list|()
block|{
return|return
name|fieldNames
return|;
block|}
DECL|method|getRandValues
specifier|public
name|RandVal
index|[]
name|getRandValues
parameter_list|()
block|{
return|return
name|randVals
return|;
block|}
annotation|@
name|Override
DECL|method|distribSetUp
specifier|public
name|void
name|distribSetUp
parameter_list|()
throws|throws
name|Exception
block|{
name|super
operator|.
name|distribSetUp
argument_list|()
expr_stmt|;
comment|// can help to hide this when testing and looking at logs
comment|//ignoreException("shard update error");
name|useFactory
argument_list|(
literal|"solr.StandardDirectoryFactory"
argument_list|)
expr_stmt|;
block|}
DECL|method|ChaosMonkeyNothingIsSafeWithPullReplicasTest
specifier|public
name|ChaosMonkeyNothingIsSafeWithPullReplicasTest
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
name|numPullReplicas
operator|=
name|random
argument_list|()
operator|.
name|nextInt
argument_list|(
name|TEST_NIGHTLY
condition|?
literal|2
else|:
literal|1
argument_list|)
operator|+
literal|1
expr_stmt|;
name|numRealtimeOrTlogReplicas
operator|=
name|random
argument_list|()
operator|.
name|nextInt
argument_list|(
name|TEST_NIGHTLY
condition|?
literal|4
else|:
literal|3
argument_list|)
operator|+
literal|1
expr_stmt|;
name|sliceCount
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"solr.tests.cloud.cm.slicecount"
argument_list|,
literal|"-1"
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sliceCount
operator|==
operator|-
literal|1
condition|)
block|{
name|sliceCount
operator|=
name|random
argument_list|()
operator|.
name|nextInt
argument_list|(
name|TEST_NIGHTLY
condition|?
literal|3
else|:
literal|2
argument_list|)
operator|+
literal|1
expr_stmt|;
block|}
name|int
name|numNodes
init|=
name|sliceCount
operator|*
operator|(
name|numRealtimeOrTlogReplicas
operator|+
name|numPullReplicas
operator|)
decl_stmt|;
name|fixShardCount
argument_list|(
name|numNodes
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"Starting ChaosMonkey test with {} shards and {} nodes"
argument_list|,
name|sliceCount
argument_list|,
name|numNodes
argument_list|)
expr_stmt|;
comment|// None of the operations used here are particularly costly, so this should work.
comment|// Using this low timeout will also help us catch index stalling.
name|clientSoTimeout
operator|=
literal|5000
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|useTlogReplicas
specifier|protected
name|boolean
name|useTlogReplicas
parameter_list|()
block|{
return|return
name|useTlogReplicas
return|;
block|}
annotation|@
name|Test
DECL|method|test
specifier|public
name|void
name|test
parameter_list|()
throws|throws
name|Exception
block|{
name|cloudClient
operator|.
name|setSoTimeout
argument_list|(
name|clientSoTimeout
argument_list|)
expr_stmt|;
name|DocCollection
name|docCollection
init|=
name|cloudClient
operator|.
name|getZkStateReader
argument_list|()
operator|.
name|getClusterState
argument_list|()
operator|.
name|getCollection
argument_list|(
name|DEFAULT_COLLECTION
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
name|this
operator|.
name|sliceCount
argument_list|,
name|docCollection
operator|.
name|getSlices
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|Slice
name|s
init|=
name|docCollection
operator|.
name|getSlice
argument_list|(
literal|"shard1"
argument_list|)
decl_stmt|;
name|assertNotNull
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"Unexpected number of replicas. Collection: "
operator|+
name|docCollection
argument_list|,
name|numRealtimeOrTlogReplicas
operator|+
name|numPullReplicas
argument_list|,
name|s
operator|.
name|getReplicas
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"Unexpected number of pull replicas. Collection: "
operator|+
name|docCollection
argument_list|,
name|numPullReplicas
argument_list|,
name|s
operator|.
name|getReplicas
argument_list|(
name|EnumSet
operator|.
name|of
argument_list|(
name|Replica
operator|.
name|Type
operator|.
name|PULL
argument_list|)
argument_list|)
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|useTlogReplicas
argument_list|()
condition|?
literal|0
else|:
name|numRealtimeOrTlogReplicas
argument_list|,
name|s
operator|.
name|getReplicas
argument_list|(
name|EnumSet
operator|.
name|of
argument_list|(
name|Replica
operator|.
name|Type
operator|.
name|NRT
argument_list|)
argument_list|)
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|useTlogReplicas
argument_list|()
condition|?
name|numRealtimeOrTlogReplicas
else|:
literal|0
argument_list|,
name|s
operator|.
name|getReplicas
argument_list|(
name|EnumSet
operator|.
name|of
argument_list|(
name|Replica
operator|.
name|Type
operator|.
name|TLOG
argument_list|)
argument_list|)
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|boolean
name|testSuccessful
init|=
literal|false
decl_stmt|;
try|try
block|{
name|handle
operator|.
name|clear
argument_list|()
expr_stmt|;
name|handle
operator|.
name|put
argument_list|(
literal|"timestamp"
argument_list|,
name|SKIPVAL
argument_list|)
expr_stmt|;
name|ZkStateReader
name|zkStateReader
init|=
name|cloudClient
operator|.
name|getZkStateReader
argument_list|()
decl_stmt|;
comment|// make sure we have leaders for each shard
for|for
control|(
name|int
name|j
init|=
literal|1
init|;
name|j
operator|<
name|sliceCount
condition|;
name|j
operator|++
control|)
block|{
name|zkStateReader
operator|.
name|getLeaderRetry
argument_list|(
name|DEFAULT_COLLECTION
argument_list|,
literal|"shard"
operator|+
name|j
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
block|}
comment|// make sure we again have leaders for each shard
name|waitForRecoveriesToFinish
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// we cannot do delete by query
comment|// as it's not supported for recovery
name|del
argument_list|(
literal|"*:*"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|StoppableThread
argument_list|>
name|threads
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|StoppableIndexingThread
argument_list|>
name|indexTreads
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|int
name|threadCount
init|=
name|TEST_NIGHTLY
condition|?
literal|3
else|:
literal|1
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|threadCount
condition|;
name|i
operator|++
control|)
block|{
name|StoppableIndexingThread
name|indexThread
init|=
operator|new
name|StoppableIndexingThread
argument_list|(
name|controlClient
argument_list|,
name|cloudClient
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|i
argument_list|)
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|threads
operator|.
name|add
argument_list|(
name|indexThread
argument_list|)
expr_stmt|;
name|indexTreads
operator|.
name|add
argument_list|(
name|indexThread
argument_list|)
expr_stmt|;
name|indexThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
name|threadCount
operator|=
literal|1
expr_stmt|;
name|i
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|threadCount
condition|;
name|i
operator|++
control|)
block|{
name|StoppableSearchThread
name|searchThread
init|=
operator|new
name|StoppableSearchThread
argument_list|(
name|cloudClient
argument_list|)
decl_stmt|;
name|threads
operator|.
name|add
argument_list|(
name|searchThread
argument_list|)
expr_stmt|;
name|searchThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|usually
argument_list|()
condition|)
block|{
name|StoppableCommitThread
name|commitThread
init|=
operator|new
name|StoppableCommitThread
argument_list|(
name|cloudClient
argument_list|,
literal|1000
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|threads
operator|.
name|add
argument_list|(
name|commitThread
argument_list|)
expr_stmt|;
name|commitThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|// TODO: we only do this sometimes so that we can sometimes compare against control,
comment|// it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer
name|boolean
name|runFullThrottle
init|=
name|random
argument_list|()
operator|.
name|nextBoolean
argument_list|()
decl_stmt|;
if|if
condition|(
name|runFullThrottle
condition|)
block|{
name|FullThrottleStoppableIndexingThread
name|ftIndexThread
init|=
operator|new
name|FullThrottleStoppableIndexingThread
argument_list|(
name|controlClient
argument_list|,
name|cloudClient
argument_list|,
name|clients
argument_list|,
literal|"ft1"
argument_list|,
literal|true
argument_list|,
name|this
operator|.
name|clientSoTimeout
argument_list|)
decl_stmt|;
name|threads
operator|.
name|add
argument_list|(
name|ftIndexThread
argument_list|)
expr_stmt|;
name|ftIndexThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
name|chaosMonkey
operator|.
name|startTheMonkey
argument_list|(
literal|true
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
try|try
block|{
name|long
name|runLength
decl_stmt|;
if|if
condition|(
name|RUN_LENGTH
operator|!=
operator|-
literal|1
condition|)
block|{
name|runLength
operator|=
name|RUN_LENGTH
expr_stmt|;
block|}
else|else
block|{
name|int
index|[]
name|runTimes
decl_stmt|;
if|if
condition|(
name|TEST_NIGHTLY
condition|)
block|{
name|runTimes
operator|=
operator|new
name|int
index|[]
block|{
literal|5000
block|,
literal|6000
block|,
literal|10000
block|,
literal|15000
block|,
literal|25000
block|,
literal|30000
block|,
literal|30000
block|,
literal|45000
block|,
literal|90000
block|,
literal|120000
block|}
expr_stmt|;
block|}
else|else
block|{
name|runTimes
operator|=
operator|new
name|int
index|[]
block|{
literal|5000
block|,
literal|7000
block|,
literal|15000
block|}
expr_stmt|;
block|}
name|runLength
operator|=
name|runTimes
index|[
name|random
argument_list|()
operator|.
name|nextInt
argument_list|(
name|runTimes
operator|.
name|length
operator|-
literal|1
argument_list|)
index|]
expr_stmt|;
block|}
name|ChaosMonkey
operator|.
name|wait
argument_list|(
name|runLength
argument_list|,
name|DEFAULT_COLLECTION
argument_list|,
name|zkStateReader
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|chaosMonkey
operator|.
name|stopTheMonkey
argument_list|()
expr_stmt|;
block|}
comment|// ideally this should go into chaosMonkey
name|restartZk
argument_list|(
literal|1000
operator|*
operator|(
literal|5
operator|+
name|random
argument_list|()
operator|.
name|nextInt
argument_list|(
literal|4
argument_list|)
operator|)
argument_list|)
expr_stmt|;
for|for
control|(
name|StoppableThread
name|indexThread
range|:
name|threads
control|)
block|{
name|indexThread
operator|.
name|safeStop
argument_list|()
expr_stmt|;
block|}
comment|// start any downed jetties to be sure we still will end up with a leader per shard...
comment|// wait for stop...
for|for
control|(
name|StoppableThread
name|indexThread
range|:
name|threads
control|)
block|{
name|indexThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
comment|// try and wait for any replications and what not to finish...
name|ChaosMonkey
operator|.
name|wait
argument_list|(
literal|2000
argument_list|,
name|DEFAULT_COLLECTION
argument_list|,
name|zkStateReader
argument_list|)
expr_stmt|;
comment|// wait until there are no recoveries...
name|waitForThingsToLevelOut
argument_list|(
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
comment|//Math.round((runLength / 1000.0f / 3.0f)));
comment|// make sure we again have leaders for each shard
for|for
control|(
name|int
name|j
init|=
literal|1
init|;
name|j
operator|<
name|sliceCount
condition|;
name|j
operator|++
control|)
block|{
name|zkStateReader
operator|.
name|getLeaderRetry
argument_list|(
name|DEFAULT_COLLECTION
argument_list|,
literal|"shard"
operator|+
name|j
argument_list|,
literal|30000
argument_list|)
expr_stmt|;
block|}
name|commit
argument_list|()
expr_stmt|;
comment|// TODO: assert we didnt kill everyone
name|zkStateReader
operator|.
name|updateLiveNodes
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
name|zkStateReader
operator|.
name|getClusterState
argument_list|()
operator|.
name|getLiveNodes
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|0
argument_list|)
expr_stmt|;
comment|// we expect full throttle fails, but cloud client should not easily fail
for|for
control|(
name|StoppableThread
name|indexThread
range|:
name|threads
control|)
block|{
if|if
condition|(
name|indexThread
operator|instanceof
name|StoppableIndexingThread
operator|&&
operator|!
operator|(
name|indexThread
operator|instanceof
name|FullThrottleStoppableIndexingThread
operator|)
condition|)
block|{
name|int
name|failCount
init|=
operator|(
operator|(
name|StoppableIndexingThread
operator|)
name|indexThread
operator|)
operator|.
name|getFailCount
argument_list|()
decl_stmt|;
name|assertFalse
argument_list|(
literal|"There were too many update fails ("
operator|+
name|failCount
operator|+
literal|"> "
operator|+
name|FAIL_TOLERANCE
operator|+
literal|") - we expect it can happen, but shouldn't easily"
argument_list|,
name|failCount
operator|>
name|FAIL_TOLERANCE
argument_list|)
expr_stmt|;
block|}
block|}
name|waitForReplicationFromReplicas
argument_list|(
name|DEFAULT_COLLECTION
argument_list|,
name|zkStateReader
argument_list|,
operator|new
name|TimeOut
argument_list|(
literal|30
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
argument_list|)
expr_stmt|;
comment|//      waitForAllWarmingSearchers();
name|Set
argument_list|<
name|String
argument_list|>
name|addFails
init|=
name|getAddFails
argument_list|(
name|indexTreads
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|deleteFails
init|=
name|getDeleteFails
argument_list|(
name|indexTreads
argument_list|)
decl_stmt|;
comment|// full throttle thread can
comment|// have request fails
name|checkShardConsistency
argument_list|(
operator|!
name|runFullThrottle
argument_list|,
literal|true
argument_list|,
name|addFails
argument_list|,
name|deleteFails
argument_list|)
expr_stmt|;
name|long
name|ctrlDocs
init|=
name|controlClient
operator|.
name|query
argument_list|(
operator|new
name|SolrQuery
argument_list|(
literal|"*:*"
argument_list|)
argument_list|)
operator|.
name|getResults
argument_list|()
operator|.
name|getNumFound
argument_list|()
decl_stmt|;
comment|// ensure we have added more than 0 docs
name|long
name|cloudClientDocs
init|=
name|cloudClient
operator|.
name|query
argument_list|(
operator|new
name|SolrQuery
argument_list|(
literal|"*:*"
argument_list|)
argument_list|)
operator|.
name|getResults
argument_list|()
operator|.
name|getNumFound
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Found "
operator|+
name|ctrlDocs
operator|+
literal|" control docs"
argument_list|,
name|cloudClientDocs
operator|>
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|VERBOSE
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"control docs:"
operator|+
name|controlClient
operator|.
name|query
argument_list|(
operator|new
name|SolrQuery
argument_list|(
literal|"*:*"
argument_list|)
argument_list|)
operator|.
name|getResults
argument_list|()
operator|.
name|getNumFound
argument_list|()
operator|+
literal|"\n\n"
argument_list|)
expr_stmt|;
comment|// try and make a collection to make sure the overseer has survived the expiration and session loss
comment|// sometimes we restart zookeeper as well
if|if
condition|(
name|random
argument_list|()
operator|.
name|nextBoolean
argument_list|()
condition|)
block|{
name|restartZk
argument_list|(
literal|1000
operator|*
operator|(
literal|5
operator|+
name|random
argument_list|()
operator|.
name|nextInt
argument_list|(
literal|4
argument_list|)
operator|)
argument_list|)
expr_stmt|;
block|}
try|try
init|(
name|CloudSolrClient
name|client
init|=
name|createCloudClient
argument_list|(
literal|"collection1"
argument_list|)
init|)
block|{
comment|// We don't really know how many live nodes we have at this point, so "maxShardsPerNode" needs to be> 1
name|createCollection
argument_list|(
literal|null
argument_list|,
literal|"testcollection"
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
literal|10
argument_list|,
name|client
argument_list|,
literal|null
argument_list|,
literal|"conf1"
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|Integer
argument_list|>
name|numShardsNumReplicas
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|numShardsNumReplicas
operator|.
name|add
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|numShardsNumReplicas
operator|.
name|add
argument_list|(
literal|1
operator|+
name|getPullReplicaCount
argument_list|()
argument_list|)
expr_stmt|;
name|checkForCollection
argument_list|(
literal|"testcollection"
argument_list|,
name|numShardsNumReplicas
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|testSuccessful
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|testSuccessful
condition|)
block|{
name|logReplicaTypesReplicationInfo
argument_list|(
name|DEFAULT_COLLECTION
argument_list|,
name|cloudClient
operator|.
name|getZkStateReader
argument_list|()
argument_list|)
expr_stmt|;
name|printLayout
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|method|getAddFails
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|getAddFails
parameter_list|(
name|List
argument_list|<
name|StoppableIndexingThread
argument_list|>
name|threads
parameter_list|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|addFails
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|StoppableIndexingThread
name|thread
range|:
name|threads
control|)
block|{
name|addFails
operator|.
name|addAll
argument_list|(
name|thread
operator|.
name|getAddFails
argument_list|()
argument_list|)
expr_stmt|;
comment|//      addFails.addAll(thread.getAddFailsMinRf());
block|}
return|return
name|addFails
return|;
block|}
DECL|method|getDeleteFails
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|getDeleteFails
parameter_list|(
name|List
argument_list|<
name|StoppableIndexingThread
argument_list|>
name|threads
parameter_list|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|deleteFails
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|StoppableIndexingThread
name|thread
range|:
name|threads
control|)
block|{
name|deleteFails
operator|.
name|addAll
argument_list|(
name|thread
operator|.
name|getDeleteFails
argument_list|()
argument_list|)
expr_stmt|;
comment|//      deleteFails.addAll(thread.getDeleteFailsMinRf());
block|}
return|return
name|deleteFails
return|;
block|}
comment|// skip the randoms - they can deadlock...
annotation|@
name|Override
DECL|method|indexr
specifier|protected
name|void
name|indexr
parameter_list|(
name|Object
modifier|...
name|fields
parameter_list|)
throws|throws
name|Exception
block|{
name|SolrInputDocument
name|doc
init|=
name|getDoc
argument_list|(
name|fields
argument_list|)
decl_stmt|;
name|indexDoc
argument_list|(
name|doc
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

